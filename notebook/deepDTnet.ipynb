{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation en diverses étapes de l'algorithme deepDTnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing co-occurence matrices (PCO) with random surfing with return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(M):\n",
    "    #Put diagonal elements to 0\n",
    "    M  = M - np.diag(np.diag(M))\n",
    "    \n",
    "    #Normalizing by row\n",
    "    D_inv = np.diag(np.reciprocal(np.sum(M,axis=0)))\n",
    "    M = np.dot(D_inv,  M)\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCO(A, K, alpha):\n",
    "    \"\"\"\n",
    "    For a graph represented by its adjacency matrix *A*, computes the co-occurence matrix by random \n",
    "    surfing on the graph with returns. 1-alpha is the probability to make, at each step, a return \n",
    "    to the original step.\n",
    "    \"\"\"\n",
    "    A=np.array(A, dtype=float)\n",
    "    \n",
    "    #The adjacency matrix A is first normalized\n",
    "    A=normalize(A) \n",
    "    \n",
    "    print(A)\n",
    "    n=A.shape[0]\n",
    "    \n",
    "    I=np.eye(n)\n",
    "    \n",
    "    P=I\n",
    "    M=np.zeros((n, n))\n",
    "    \n",
    "    for i in range(K):\n",
    "        P = alpha*np.dot(P,A) + (1-alpha)*I\n",
    "        print(P)\n",
    "        M = M+P\n",
    "    \n",
    "    return(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.5 0.5]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "[[0.4 0.3 0.3]\n",
      " [0.3 0.4 0.3]\n",
      " [0.3 0.3 0.4]]\n",
      "[[0.58 0.21 0.21]\n",
      " [0.21 0.58 0.21]\n",
      " [0.21 0.21 0.58]]\n",
      "[[0.526 0.237 0.237]\n",
      " [0.237 0.526 0.237]\n",
      " [0.237 0.237 0.526]]\n",
      "[[0.5422 0.2289 0.2289]\n",
      " [0.2289 0.5422 0.2289]\n",
      " [0.2289 0.2289 0.5422]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0482, 0.9759, 0.9759],\n",
       "       [0.9759, 2.0482, 0.9759],\n",
       "       [0.9759, 0.9759, 2.0482]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCO([[0,1,1],[1,0,1],[1,1,0]], 4, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From co-occurence matrices (PCO) to shifted positive pointwise mutual information (PPMI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PPMI(M):\n",
    "    \"\"\"Computes the shifted positive pointwise mutual information (PPMI) matrix\n",
    "    from the co-occurence matrix (PCO) of a graph.\"\"\"\n",
    "    \n",
    "    M=normalize(M)\n",
    "    cols = np.sum(M, axis=0)\n",
    "    rows = np.sum(M, axis=1).reshape((-1,1))\n",
    "    s = np.sum(rows)\n",
    "    \n",
    "    P = s*M\n",
    "    P /= cols\n",
    "    P /= rows\n",
    "    \n",
    "    #P[np.where(P<0)] = 1.0\n",
    "    P = np.log(P)\n",
    "\n",
    "    #To avoid NaN when applying log\n",
    "    P[np.isnan(P)] = 0.0\n",
    "    P[np.isinf(P)] = 0.0\n",
    "    P[np.isneginf(P)] = 0.0\n",
    "    P[np.where(P<0)] = 0.0\n",
    "    \n",
    "    return(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.5 0.5]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "[[0.6 0.2 0.2]\n",
      " [0.2 0.6 0.2]\n",
      " [0.2 0.2 0.6]]\n",
      "[[0.68 0.16 0.16]\n",
      " [0.16 0.68 0.16]\n",
      " [0.16 0.16 0.68]]\n",
      "[[0.664 0.168 0.168]\n",
      " [0.168 0.664 0.168]\n",
      " [0.168 0.168 0.664]]\n",
      "[[0.6672 0.1664 0.1664]\n",
      " [0.1664 0.6672 0.1664]\n",
      " [0.1664 0.1664 0.6672]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.40546511, 0.40546511],\n",
       "       [0.40546511, 0.        , 0.40546511],\n",
       "       [0.40546511, 0.40546511, 0.        ]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPMI(PCO([[0,1,1],[1,0,1],[1,1,0]], 4, 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding with stacked denoising autoencoders (SDAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"from https://discuss.pytorch.org/t/writing-a-simple-gaussian-noise-layer-in-pytorch/4694/4\"\"\"\n",
    "    def __init__(self, stddev):\n",
    "        super().__init__()\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def forward(self, din):\n",
    "        if self.training:\n",
    "            return din + torch.randn(din.size()) * self.stddev\n",
    "        return din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_shape, n_neurons, stddev=None):\n",
    "        super().__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.dense_layer = nn.Linear(self.input_shape, self.n_neurons)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.has_noise = False\n",
    "        \n",
    "        if stddev is not None:\n",
    "            self.has_noise = True\n",
    "            self.noise = GaussianNoise(stddev)\n",
    "\n",
    "    def forward(self, features):\n",
    "        x = self.dense_layer(features)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        if self.has_noise:\n",
    "            x = self.noise(x)\n",
    "        \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDAE(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_layers):\n",
    "        super().__init__()\n",
    "        self.inputs = [input_shape] + hidden_layers\n",
    "        \n",
    "        n = len(self.inputs)\n",
    "        encoder_units = [BasicBlock(self.inputs[i], self.inputs[i+1], stddev=0.2) for i in range(n-1)]\n",
    "        \n",
    "        self.encoder = nn.Sequential(*encoder_units)\n",
    "        \n",
    "        decoder_units = [BasicBlock(self.inputs[i], self.inputs[i-1]) for i in range(n-1,1,-1)]\n",
    "        decoder_units.extend([nn.Linear(self.inputs[1], self.inputs[0]), nn.Sigmoid()])\n",
    "        \n",
    "        self.decoder = nn.Sequential(*decoder_units)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        encoded = self.encoder(features)\n",
    "        \n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = SDAE(784, [372, 186, 93]).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 372]         292,020\n",
      "              ReLU-2                  [-1, 372]               0\n",
      "     GaussianNoise-3                  [-1, 372]               0\n",
      "        BasicBlock-4                  [-1, 372]               0\n",
      "            Linear-5                  [-1, 186]          69,378\n",
      "              ReLU-6                  [-1, 186]               0\n",
      "     GaussianNoise-7                  [-1, 186]               0\n",
      "        BasicBlock-8                  [-1, 186]               0\n",
      "            Linear-9                   [-1, 93]          17,391\n",
      "             ReLU-10                   [-1, 93]               0\n",
      "    GaussianNoise-11                   [-1, 93]               0\n",
      "       BasicBlock-12                   [-1, 93]               0\n",
      "           Linear-13                  [-1, 186]          17,484\n",
      "             ReLU-14                  [-1, 186]               0\n",
      "       BasicBlock-15                  [-1, 186]               0\n",
      "           Linear-16                  [-1, 372]          69,564\n",
      "             ReLU-17                  [-1, 372]               0\n",
      "       BasicBlock-18                  [-1, 372]               0\n",
      "           Linear-19                  [-1, 784]         292,432\n",
      "          Sigmoid-20                  [-1, 784]               0\n",
      "================================================================\n",
      "Total params: 758,269\n",
      "Trainable params: 758,269\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 2.89\n",
      "Estimated Total Size (MB): 2.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes=list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img     # unnormalize\n",
    "    #npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.059\n",
      "[1,  4000] loss: 0.044\n",
      "[1,  6000] loss: 0.038\n",
      "[1,  8000] loss: 0.035\n",
      "[1, 10000] loss: 0.034\n",
      "[1, 12000] loss: 0.033\n",
      "[1, 14000] loss: 0.031\n",
      "[1, 16000] loss: 0.031\n",
      "[1, 18000] loss: 0.030\n",
      "[1, 20000] loss: 0.028\n",
      "[1, 22000] loss: 0.029\n",
      "[1, 24000] loss: 0.028\n",
      "[1, 26000] loss: 0.028\n",
      "[1, 28000] loss: 0.027\n",
      "[1, 30000] loss: 0.027\n",
      "[1, 32000] loss: 0.026\n",
      "[1, 34000] loss: 0.026\n",
      "[1, 36000] loss: 0.026\n",
      "[1, 38000] loss: 0.026\n",
      "[1, 40000] loss: 0.026\n",
      "[1, 42000] loss: 0.025\n",
      "[1, 44000] loss: 0.025\n",
      "[1, 46000] loss: 0.025\n",
      "[1, 48000] loss: 0.024\n",
      "[1, 50000] loss: 0.025\n",
      "[1, 52000] loss: 0.024\n",
      "[1, 54000] loss: 0.024\n",
      "[1, 56000] loss: 0.024\n",
      "[1, 58000] loss: 0.024\n",
      "[1, 60000] loss: 0.024\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs=torch.flatten(inputs)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    print(inputs.shape)\n",
    "    imshow(torchvision.utils.make_grid(inputs).numpy())     \n",
    "    \n",
    "    inputs=torch.flatten(inputs)\n",
    "        # zero the parameter gradients\n",
    "        # forward + backward + optimize\n",
    "    \n",
    "    inputs_noise=GaussianNoise(0.2)(inputs).reshape((1,1,28,28))\n",
    "    imshow(torchvision.utils.make_grid(inputs_noise).detach().numpy())\n",
    "    \n",
    "    outputs = model(inputs).reshape((1, 1, 28, 28))\n",
    "    \n",
    "    imshow(torchvision.utils.make_grid(outputs).detach().numpy())     \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PU-Learning via matrix completion and convex optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PU Learning\n",
    "\n",
    "k = 7\n",
    "Fd = 20\n",
    "Ft = 20\n",
    "\n",
    "#Number of variables\n",
    "N_variables = Fd * k + Ft * k\n",
    "\n",
    "#Because scipy's minimize needs a (n,) array of variables\n",
    "mat_compo = {}\n",
    "compo_mat = []\n",
    "p=0\n",
    "\n",
    "for c in ['H', 'W']:\n",
    "    for i in range(Fd if c=='H' else Ft):\n",
    "        for j in range(k):\n",
    "            mat_compo[(c, i, j)] = p\n",
    "            compo_mat.append((c, i, j))\n",
    "            p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd = 20\n",
    "Nt = 20\n",
    "\n",
    "p = np.eye(20, dtype=float)\n",
    "x = np.random.randn(Nd,Fd)\n",
    "y = np.random.randn(Nt,Ft)\n",
    "\n",
    "alpha = 0.2\n",
    "gamma = 0.3\n",
    "\n",
    "Ipos = [(i,i) for i in range(min(Nd,Nt))]\n",
    "Ineg = [(i,j) for i in range(Nd) for j in range(Nt) if (i,j) not in Ipos]\n",
    "I = Ipos + Ineg\n",
    "\n",
    "def objective(z):\n",
    "    res=0\n",
    "    \n",
    "    H = np.zeros((Fd,k), dtype=float)\n",
    "    W = np.zeros((Ft,k), dtype=float)\n",
    "    \n",
    "    for i in range(Fd):\n",
    "        for j in range(k):\n",
    "            H[i,j]=z[mat_compo[('H', i, j)]]\n",
    "            \n",
    "    for i in range(Ft):\n",
    "        for j in range(k):\n",
    "            W[i,j]=z[mat_compo[('W', i, j)]]\n",
    "         \n",
    "    for (i,j) in Ipos:\n",
    "        res += (p[i,j]- np.dot(np.dot(x[i,:], (H @ np.transpose(W))), y[:,j]))**2\n",
    "    for (i,j) in Ineg:\n",
    "        res += alpha*(p[i,j]- np.dot(np.dot(x[i,:], (H @ np.transpose(W))), y[:,j]))**2\n",
    "    \n",
    "    Sreg = gamma/2 * (np.linalg.norm(H) + np.linalg.norm(W))\n",
    "    \n",
    "    res += Sreg\n",
    "    \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 6.829665\n",
      "         Iterations: 1000\n",
      "         Function evaluations: 284538\n",
      "         Gradient evaluations: 1009\n"
     ]
    }
   ],
   "source": [
    "res = minimize(objective,x0 = np.random.randn(N_variables), options={'maxiter':1000, 'disp':'True'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2156256971064746\n",
      "0.32101247399922694\n",
      "-0.08885838184022438\n",
      "0.08233132094469015\n",
      "0.062120094941989355\n",
      "-0.3769398966190506\n",
      "-0.16007070675968857\n",
      "-0.1175141503312301\n",
      "0.3132671197931596\n",
      "0.12212999909888365\n",
      "0.18886774771029252\n",
      "0.1406524958251719\n",
      "0.34237874607068397\n",
      "-0.2840154424597365\n",
      "0.04800438015653148\n",
      "-0.11207551752224493\n",
      "0.03384893586862922\n",
      "0.27059663352276064\n",
      "-0.48687662827390343\n",
      "0.19229498628662084\n",
      "-0.2630780666249034\n",
      "0.11850204407581913\n",
      "0.1061514311398693\n",
      "-0.1488636535906391\n",
      "0.2101892946283354\n",
      "-0.08611401275830777\n",
      "0.3248914544289978\n",
      "0.22064895828783526\n",
      "-0.21372587896585798\n",
      "0.28920854715348643\n",
      "0.2303915437191929\n",
      "0.43439703814341285\n",
      "-0.1169274019061948\n",
      "0.3577067468410794\n",
      "0.18783391568892388\n",
      "0.045509432547769624\n",
      "-0.2095365695838818\n",
      "-0.14464879335870995\n",
      "0.32321428325492335\n",
      "-0.24325847533612158\n",
      "-0.1266791676258012\n",
      "0.4080895645803141\n",
      "0.039041491129598496\n",
      "0.009295704832545992\n",
      "-0.34240381593296176\n",
      "-0.059335308473098064\n",
      "-0.042737677874143565\n",
      "0.2350307312628195\n",
      "0.020343417516329065\n",
      "0.08741020561189941\n",
      "-0.20714371932758407\n",
      "0.06017643476629825\n",
      "0.12146295965254293\n",
      "-0.21721329901272735\n",
      "-0.39402268954614283\n",
      "0.40856098545937314\n",
      "-0.1397487803420088\n",
      "-0.0943856116299812\n",
      "0.08962819803646627\n",
      "-0.13941016581082954\n",
      "-0.25712302294731143\n",
      "0.6068882519759633\n",
      "0.13940391442309927\n",
      "0.00978498176056436\n",
      "0.017476620834715698\n",
      "-0.39193123189533\n",
      "0.05599220495116169\n",
      "-0.13934435014926005\n",
      "0.34727211861355284\n",
      "0.2703174430903042\n",
      "-0.17670747319705232\n",
      "0.04494868324274062\n",
      "0.1513182578408119\n",
      "-0.2614322148203796\n",
      "0.004160865965042504\n",
      "0.07934092495863748\n",
      "0.08358124674334837\n",
      "0.11750505819648614\n",
      "0.3921577474954172\n",
      "-0.24177659465368945\n",
      "-0.2805306537099777\n",
      "0.35833859442937727\n",
      "-0.42930938466753354\n",
      "0.12143806899808586\n",
      "0.014038607979863268\n",
      "-0.2276867665679331\n",
      "-0.012798702535273349\n",
      "-0.2107038537708888\n",
      "0.06310262559897968\n",
      "-0.14400745671626872\n",
      "0.225085768815943\n",
      "-0.32014522709334514\n",
      "-0.2620225437400775\n",
      "0.005213717303562043\n",
      "0.16250957336138247\n",
      "0.06331896309049487\n",
      "-0.1582144626572694\n",
      "0.03139373138862231\n",
      "0.623996365847286\n",
      "-0.2960814932530168\n",
      "-0.13682852587302616\n",
      "0.0797227714888547\n",
      "-0.15912874159357604\n",
      "-0.4148031243719279\n",
      "0.1282024936380529\n",
      "-0.23998991544754072\n",
      "0.20662424688679268\n",
      "0.2392616057872741\n",
      "-0.2520104941072222\n",
      "-0.08648562380629338\n",
      "-0.04370167181007828\n",
      "-0.21588690785862014\n",
      "0.17246886087458826\n",
      "-0.057763914384075965\n",
      "-0.3558440777817268\n",
      "0.19627440069370666\n",
      "0.005859764802829848\n",
      "0.15749440509269286\n",
      "0.35593169994935736\n",
      "-0.11310238447958493\n",
      "-0.33890771114372087\n",
      "0.08278882560691403\n",
      "-0.22032181040486534\n",
      "-0.2854933708958344\n",
      "0.1852701796285125\n",
      "0.22989581878754703\n",
      "-0.03237624631339636\n",
      "0.1284048835568754\n",
      "0.1534494057708935\n",
      "0.08785461819671311\n",
      "-0.1670092610604318\n",
      "-0.02854383661825194\n",
      "0.5071262436795254\n",
      "-0.16983984656071738\n",
      "-0.08223009426661355\n",
      "-0.35275452885184055\n",
      "0.009247167007078005\n",
      "-0.42188838582189253\n",
      "0.07188960428143948\n",
      "-0.3195989511125301\n",
      "0.18557237836377555\n",
      "-0.2722449976514071\n",
      "-0.1489999773432108\n",
      "-0.04739275851427904\n",
      "-0.19744653356129435\n",
      "-0.08033434791496197\n",
      "0.295427049571264\n",
      "0.20376622308916592\n",
      "-0.15228878978462956\n",
      "0.2750948375850163\n",
      "0.029646380413555655\n",
      "-0.3386084052171674\n",
      "-0.09949696114970111\n",
      "0.31583329600244314\n",
      "-0.09982727953794669\n",
      "0.03558127325156643\n",
      "0.11147481960563849\n",
      "-0.1356272898003691\n",
      "0.096637360467501\n",
      "0.20800834671392202\n",
      "0.009413826063298214\n",
      "0.10131400348300279\n",
      "-0.15773718193625216\n",
      "-0.12173907053317858\n",
      "-0.06084618905147682\n",
      "0.19424944273869288\n",
      "0.5941659905295124\n",
      "0.08955338278738433\n",
      "-0.3602397986504336\n",
      "-0.3579514889996744\n",
      "-0.29588911925795214\n",
      "0.3048392661323286\n",
      "0.2521828599067393\n",
      "-0.05464149510538652\n",
      "-0.36373186585508455\n",
      "0.003752614761238046\n",
      "-0.3885665576444708\n",
      "-0.1878380608196771\n",
      "-0.27661149327942536\n",
      "0.02049427061271729\n",
      "0.3044705433655105\n",
      "0.12026889484961567\n",
      "0.02043301743626499\n",
      "0.027778710554051213\n",
      "-0.14094716990970896\n",
      "-0.18761951470678898\n",
      "0.36849041760329493\n",
      "0.11609600176244975\n",
      "-0.30177231316173136\n",
      "-0.11726451037989766\n",
      "0.12247564488527297\n",
      "-0.2563282258125359\n",
      "0.24745934862994995\n",
      "0.03969417151630705\n",
      "-0.20730920365018923\n",
      "0.13455610783378535\n",
      "-0.26574813633882266\n",
      "-0.14689826123413813\n",
      "0.08753369968197167\n",
      "0.29476819649488994\n",
      "-0.24577498444599719\n",
      "0.136399351213393\n",
      "-0.33822548144125497\n",
      "0.05810949922673109\n",
      "-0.14371473873246068\n",
      "0.39366401922068395\n",
      "-0.3966730063998505\n",
      "-0.12657413161091643\n",
      "-0.17681723883996842\n",
      "0.19411878718990097\n",
      "0.3353345432823114\n",
      "0.014294239372396197\n",
      "-0.11535260249137062\n",
      "-0.007303652203645074\n",
      "-0.23253269778900054\n",
      "0.1896183551402384\n",
      "-0.06436482663524504\n",
      "-0.14511312241586688\n",
      "0.11860516635906816\n",
      "-0.23735651398338348\n",
      "0.5137022277496277\n",
      "0.03355226189787286\n",
      "0.3196951405187839\n",
      "0.11304601496539818\n",
      "0.1499063921418184\n",
      "0.359236887434552\n",
      "0.3974115589820771\n",
      "-0.05228627567552788\n",
      "0.13602420957228695\n",
      "0.2062851165448577\n",
      "0.08569536273132831\n",
      "0.3359459582883499\n",
      "-0.19731062291008003\n",
      "0.19624375842253147\n",
      "0.20933407008102692\n",
      "-0.20152321977075044\n",
      "-0.12237507983091073\n",
      "-0.002591277509947809\n",
      "0.1551371854731254\n",
      "0.4615795005241847\n",
      "0.0025693498316562563\n",
      "0.21269824627851888\n",
      "0.02487559391624261\n",
      "0.4107691359982403\n",
      "-0.03679552691184748\n",
      "0.31712159808452345\n",
      "0.011970688705064042\n",
      "0.33308194041288824\n",
      "0.4460866107858103\n",
      "-0.1980396745795652\n",
      "0.27674332957249187\n",
      "0.05715199424254752\n",
      "0.22313608645846483\n",
      "-0.05315190951675816\n",
      "-0.08265692412006254\n",
      "-0.07159080700168832\n",
      "0.0070178109370160335\n",
      "-0.3285089543016538\n",
      "0.012693598220443386\n",
      "0.004838798550088515\n",
      "-0.5723851533074108\n",
      "0.03283461387355968\n",
      "-0.1716146832919876\n",
      "0.1303851899280749\n",
      "-0.06669526117481878\n",
      "-0.09803005352367944\n",
      "-0.24520816111378027\n",
      "-0.10510446974604695\n",
      "0.0464632828773586\n",
      "-0.16459568686984227\n",
      "-0.1300259398676554\n",
      "-0.22282333302768825\n",
      "0.1321698028449564\n",
      "0.2921929189191512\n",
      "0.1893340374261501\n",
      "-0.1332729668102819\n",
      "0.047877136671904234\n",
      "0.3290762770086457\n",
      "0.22993063686478976\n",
      "-0.5334835633733672\n",
      "0.2695979623600122\n",
      "0.14767182499636436\n",
      "0.055951806964040035\n",
      "0.24246464572173132\n",
      "-0.09169850566527471\n",
      "0.03294410987652904\n",
      "0.3378138068935207\n",
      "0.06814902604413892\n",
      "0.07682109450115931\n",
      "0.20200502281689886\n",
      "-0.05849478775982131\n",
      "0.1550112350328653\n",
      "0.23785028436433742\n",
      "0.589559830824979\n",
      "-0.21356454623506213\n",
      "-0.12913187838230206\n",
      "0.08163059049175633\n",
      "0.02803228679267882\n",
      "0.023371527953223503\n",
      "0.27426680378644014\n",
      "-0.1298840265477451\n",
      "-0.2674990458916525\n",
      "0.019455440120841272\n",
      "-0.364913971178368\n",
      "-0.10849756539600434\n",
      "0.17998224354220008\n",
      "-0.24198529418328443\n",
      "0.1504136677413892\n",
      "-0.3437769310301396\n",
      "-0.04359441615979387\n",
      "0.10149320048722818\n",
      "-0.16333178216816957\n",
      "0.08502639202924539\n",
      "0.3743457028224558\n",
      "0.431882904726105\n",
      "0.1425764461504919\n",
      "0.44663337123577235\n",
      "-0.16662064081404965\n",
      "0.15951035921486167\n",
      "-0.15306766145862105\n",
      "-0.06011100265874614\n",
      "-0.2782684272597868\n",
      "0.11069446316926518\n",
      "0.0003503254187689486\n",
      "0.09168009197297951\n",
      "-0.38995582785950245\n",
      "-0.25784092758840327\n",
      "-0.2621402664746654\n",
      "-0.2341916136944358\n",
      "-0.15063170977091078\n",
      "0.26982319293529655\n",
      "-0.3373482786296025\n",
      "0.1216055173014827\n",
      "-0.3975820531623352\n",
      "0.37442891572162906\n",
      "-0.018167226883474177\n",
      "0.12811429179753275\n",
      "0.06644191744893249\n",
      "-0.24941979599267888\n",
      "-0.04897630795847666\n",
      "0.12835472505885026\n",
      "0.035506524678362586\n",
      "0.23159412627862763\n",
      "-0.20098260503289778\n",
      "0.41113259973013955\n",
      "0.00757752906028436\n",
      "0.02199936868493456\n",
      "0.1578600781749694\n",
      "-0.02977991955203635\n",
      "0.03674444864664142\n",
      "-0.3318057346835045\n",
      "-0.3073572615307818\n",
      "-0.13456578466894797\n",
      "0.38764814633360123\n",
      "0.3216564463447149\n",
      "-0.09607734537770063\n",
      "0.2581059908521283\n",
      "0.04447636202187774\n",
      "-0.25743496773704316\n",
      "0.1262099607356721\n",
      "-0.1342079218438997\n",
      "-0.4738275075794275\n",
      "-0.1257611859212696\n",
      "-0.148916471595884\n",
      "0.06790057334155705\n",
      "0.14056884216207077\n",
      "-0.07243652562564587\n",
      "0.4982514230970061\n",
      "-0.34655855897658583\n",
      "-0.27765307614105056\n",
      "-0.10512014875542708\n",
      "-0.19905141327397557\n",
      "-0.024006150642597868\n",
      "0.022247967188228218\n",
      "-0.08221069182278498\n",
      "-0.07312933516945158\n",
      "-0.363523445255585\n",
      "0.11935978742865916\n",
      "0.05093536394034853\n",
      "-0.15290462093986734\n"
     ]
    }
   ],
   "source": [
    "z=res['x']\n",
    "H = np.zeros((Fd,k), dtype=float)\n",
    "W = np.zeros((Ft,k), dtype=float)\n",
    "    \n",
    "for i in range(Fd):\n",
    "    for j in range(k):\n",
    "        H[i,j]=z[mat_compo[('H', i, j)]]\n",
    "            \n",
    "for i in range(Ft):\n",
    "    for j in range(k):\n",
    "        W[i,j]=z[mat_compo[('W', i, j)]]\n",
    "\n",
    "H @ np.transpose(W)\n",
    "\n",
    "for i,j in Ineg:\n",
    "    print(np.dot(np.dot(x[i,:], (H @ np.transpose(W))), y[:,j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [References]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] X. Zeng, S. Zhu, W. Lu, Z. Liu, J. Huang, Y. Zhou, J. Fang, Y. Huang, H. Guo, L. Li, B. D. Trapp, R. Nussinov, C. Eng, J. Loscalzo, F. Cheng, Target identification among known drugs by deep learning from heterogeneous networks. Chem. Sci.11, 1775–1797 (2020).\n",
    "\n",
    "[2] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2016. Deep neural networks for learning graph representations. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI'16). AAAI Press, 1145–1152."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
