{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation en diverses étapes de l'algorithme deepDTnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing co-occurence matrices (PCO) with random surfing with return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(M):\n",
    "    #Put diagonal elements to 0\n",
    "    M  = M - np.diag(np.diag(M))\n",
    "    \n",
    "    #Normalizing by row\n",
    "    D_inv = np.diag(np.reciprocal(np.sum(M,axis=0)))\n",
    "    M = np.dot(D_inv,  M)\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCO(A, K, alpha):\n",
    "    \"\"\"\n",
    "    For a graph represented by its adjacency matrix *A*, computes the co-occurence matrix by random \n",
    "    surfing on the graph with returns. 1-alpha is the probability to make, at each step, a return \n",
    "    to the original step.\n",
    "    \"\"\"\n",
    "    A=np.array(A, dtype=float)\n",
    "    \n",
    "    #The adjacency matrix A is first normalized\n",
    "    A=normalize(A) \n",
    "    \n",
    "    n=A.shape[0]\n",
    "    \n",
    "    I=np.eye(n)\n",
    "    \n",
    "    P=I\n",
    "    M=np.zeros((n, n))\n",
    "    \n",
    "    for i in range(K):\n",
    "        P = alpha*np.dot(P,A) + (1-alpha)*I\n",
    "        M = M+P\n",
    "    \n",
    "    return(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.5 0.5]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "[[0.4 0.3 0.3]\n",
      " [0.3 0.4 0.3]\n",
      " [0.3 0.3 0.4]]\n",
      "[[0.58 0.21 0.21]\n",
      " [0.21 0.58 0.21]\n",
      " [0.21 0.21 0.58]]\n",
      "[[0.526 0.237 0.237]\n",
      " [0.237 0.526 0.237]\n",
      " [0.237 0.237 0.526]]\n",
      "[[0.5422 0.2289 0.2289]\n",
      " [0.2289 0.5422 0.2289]\n",
      " [0.2289 0.2289 0.5422]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0482, 0.9759, 0.9759],\n",
       "       [0.9759, 2.0482, 0.9759],\n",
       "       [0.9759, 0.9759, 2.0482]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCO([[0,1,1],[1,0,1],[1,1,0]], 4, 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From co-occurence matrices (PCO) to shifted positive pointwise mutual information (PPMI) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PPMI(M):\n",
    "    \"\"\"Computes the shifted positive pointwise mutual information (PPMI) matrix\n",
    "    from the co-occurence matrix (PCO) of a graph.\"\"\"\n",
    "    \n",
    "    M=normalize(M)\n",
    "    cols = np.sum(M, axis=0)\n",
    "    rows = np.sum(M, axis=1).reshape((-1,1))\n",
    "    s = np.sum(rows)\n",
    "    \n",
    "    P = s*M\n",
    "    P /= cols\n",
    "    P /= rows\n",
    "    \n",
    "    #P[np.where(P<0)] = 1.0\n",
    "    P = np.log(P)\n",
    "\n",
    "    #To avoid NaN when applying log\n",
    "    P[np.isnan(P)] = 0.0\n",
    "    P[np.isinf(P)] = 0.0\n",
    "    P[np.isneginf(P)] = 0.0\n",
    "    P[np.where(P<0)] = 0.0\n",
    "    \n",
    "    return(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.5 0.5]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "[[0.6 0.2 0.2]\n",
      " [0.2 0.6 0.2]\n",
      " [0.2 0.2 0.6]]\n",
      "[[0.68 0.16 0.16]\n",
      " [0.16 0.68 0.16]\n",
      " [0.16 0.16 0.68]]\n",
      "[[0.664 0.168 0.168]\n",
      " [0.168 0.664 0.168]\n",
      " [0.168 0.168 0.664]]\n",
      "[[0.6672 0.1664 0.1664]\n",
      " [0.1664 0.6672 0.1664]\n",
      " [0.1664 0.1664 0.6672]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.40546511, 0.40546511],\n",
       "       [0.40546511, 0.        , 0.40546511],\n",
       "       [0.40546511, 0.40546511, 0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPMI(PCO([[0,1,1],[1,0,1],[1,1,0]], 4, 0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding with stacked denoising autoencoders (SDAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    def __init__(self, stddev):\n",
    "        super().__init__()\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def forward(self, din):\n",
    "        if self.training:\n",
    "            return din + torch.randn(din.size()) * self.stddev\n",
    "        return din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropoutNoise(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.size = tuple(x.size())\n",
    "        \n",
    "        a = np.random.random(self.size) > self.p\n",
    "        a = np.array(a, dtype=float)\n",
    "        \n",
    "        return(x*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "DropoutNoise(0.9)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, input_shape, n_neurons, activation='relu', noise=None, noise_arg=None):\n",
    "        super().__init__()\n",
    "        self.n_neurons = n_neurons\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.has_noise = False\n",
    "        \n",
    "        if noise=='gaussian':\n",
    "            self.has_noise = True\n",
    "            self.noise = GaussianNoise(noise_arg)\n",
    "        elif noise=='dropout':\n",
    "            self.has_noise = True\n",
    "            self.noise = DropoutNoise(noise_arg)\n",
    "            \n",
    "        self.dense_layer = nn.Linear(self.input_shape, self.n_neurons)\n",
    "        \n",
    "        activations_map = {'relu':nn.ReLU, 'tanh':nn.Tanh, 'sigmoid':nn.Sigmoid}\n",
    "        self.activation = activations_map[activation]()\n",
    "\n",
    "    def forward(self, features):\n",
    "        x=features\n",
    "        \n",
    "        if self.has_noise:\n",
    "            x = self.noise(x)\n",
    "\n",
    "        x = self.dense_layer(features)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDAE(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_layers, activation='relu', last_activation='relu', noise_type='dropout', noise_arg=0.2):\n",
    "        super().__init__()\n",
    "        self.inputs = [input_shape] + hidden_layers\n",
    "        \n",
    "        n = len(self.inputs)\n",
    "        encoder_units = [BasicBlock(self.inputs[0], self.inputs[1], activation=activation, noise=noise_type, noise_arg=noise_arg)]\n",
    "        encoder_units.extend([BasicBlock(self.inputs[i], self.inputs[i+1], activation=activation) for i in range(1, n-1)])\n",
    "        \n",
    "        self.encoder = nn.Sequential(*encoder_units)\n",
    "        \n",
    "        decoder_units = [BasicBlock(self.inputs[i], self.inputs[i-1], activation=activation) for i in range(n-1,1,-1)]\n",
    "        decoder_units.append(BasicBlock(self.inputs[1], self.inputs[0], activation=last_activation))\n",
    "        \n",
    "        self.decoder = nn.Sequential(*decoder_units)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        encoded = self.encoder(features)\n",
    "        \n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the SDAE on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SDAE(784, [372, 186, 93]).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 372]         292,020\n",
      "              ReLU-2                  [-1, 372]               0\n",
      "     GaussianNoise-3                  [-1, 372]               0\n",
      "        BasicBlock-4                  [-1, 372]               0\n",
      "            Linear-5                  [-1, 186]          69,378\n",
      "              ReLU-6                  [-1, 186]               0\n",
      "     GaussianNoise-7                  [-1, 186]               0\n",
      "        BasicBlock-8                  [-1, 186]               0\n",
      "            Linear-9                   [-1, 93]          17,391\n",
      "             ReLU-10                   [-1, 93]               0\n",
      "    GaussianNoise-11                   [-1, 93]               0\n",
      "       BasicBlock-12                   [-1, 93]               0\n",
      "           Linear-13                  [-1, 186]          17,484\n",
      "             ReLU-14                  [-1, 186]               0\n",
      "       BasicBlock-15                  [-1, 186]               0\n",
      "           Linear-16                  [-1, 372]          69,564\n",
      "             ReLU-17                  [-1, 372]               0\n",
      "       BasicBlock-18                  [-1, 372]               0\n",
      "           Linear-19                  [-1, 784]         292,432\n",
      "          Sigmoid-20                  [-1, 784]               0\n",
      "================================================================\n",
      "Total params: 758,269\n",
      "Trainable params: 758,269\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 2.89\n",
      "Estimated Total Size (MB): 2.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img     # unnormalize\n",
    "    #npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.059\n",
      "[1,  4000] loss: 0.044\n",
      "[1,  6000] loss: 0.038\n",
      "[1,  8000] loss: 0.035\n",
      "[1, 10000] loss: 0.034\n",
      "[1, 12000] loss: 0.033\n",
      "[1, 14000] loss: 0.031\n",
      "[1, 16000] loss: 0.031\n",
      "[1, 18000] loss: 0.030\n",
      "[1, 20000] loss: 0.028\n",
      "[1, 22000] loss: 0.029\n",
      "[1, 24000] loss: 0.028\n",
      "[1, 26000] loss: 0.028\n",
      "[1, 28000] loss: 0.027\n",
      "[1, 30000] loss: 0.027\n",
      "[1, 32000] loss: 0.026\n",
      "[1, 34000] loss: 0.026\n",
      "[1, 36000] loss: 0.026\n",
      "[1, 38000] loss: 0.026\n",
      "[1, 40000] loss: 0.026\n",
      "[1, 42000] loss: 0.025\n",
      "[1, 44000] loss: 0.025\n",
      "[1, 46000] loss: 0.025\n",
      "[1, 48000] loss: 0.024\n",
      "[1, 50000] loss: 0.025\n",
      "[1, 52000] loss: 0.024\n",
      "[1, 54000] loss: 0.024\n",
      "[1, 56000] loss: 0.024\n",
      "[1, 58000] loss: 0.024\n",
      "[1, 60000] loss: 0.024\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs=torch.flatten(inputs)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAOGElEQVR4nO3df6jVdZ7H8dcrG8nqBpp5MUd2pugHtrHOYrKxUlY2uFHoRAzTH+W2gkNMMEJ/VEZMsCzFslMQxMQdinGXNhFSEolmKmRaCQa1X/6cMsn0ctXKwgYTU9/7x/023Kl7Pud6fnvfzwdczjnf9/l+z5tvvfx+z/n++DgiBGD8O6vbDQDoDMIOJEHYgSQIO5AEYQeSOLuTH2abn/6BNosIjza9qS277YW2/2x7t+0Hm1kWgPZyo8fZbU+Q9L6kmyXtl7RJ0p0RsaMwD1t2oM3asWWfK2l3ROyJiOOSVkla1MTyALRRM2GfIWnfiNf7q2l/w/Yy25ttb27iswA0qe0/0EXEgKQBid14oJua2bIPSpo54vX3q2kAelAzYd8k6TLbP7Q9UdLPJK1rTVsAWq3h3fiIOGH7Pkm/lzRB0nMRsb1lnQFoqYYPvTX0YXxnB9quLSfVADhzEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQREeHbMboJkyYUKxfffXVxfpZZ9X+N/v5558vzjtt2rRi/cYbbyzW33333WIdvYMtO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwXH2HmCPOujmX912223F+sKFC2vWHnjggeK8S5cuLda3bt1arN9+++3F+po1a2rWZs6cWZx3+fLlxfpTTz1VrO/du7dYz6apsNv+SNKXkk5KOhERc1rRFIDWa8WW/YaI+LQFywHQRnxnB5JoNuwh6Q+2t9heNtobbC+zvdn25iY/C0ATmt2NnxcRg7anSXrV9q6IeGPkGyJiQNKAJNmOJj8PQIOa2rJHxGD1eEjSWklzW9EUgNZrOOy2z7Pd981zST+WtK1VjQForWZ24/slra2OEZ8t6X8j4pWWdHWGOfvs8mp87LHHivXzzz+/WN+wYUOxXroeft26dcV5X3755WL91KlTxXq95ff19dWs3X333cV5r7nmmmK93vkHAwMDNWvHjx8vzjseNRz2iNgj6R9a2AuANuLQG5AEYQeSIOxAEoQdSIKwA0k4onMntY3XM+hmzJhRrO/bt69YP3HiRLH+2WefFevbt2+vWVuwYEFx3m6aN29esb5+/fpi/YILLijW77///pq1J598sjjvmSwiRr1mmi07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBraR7QL1LZCdOnFisv/nmm61sp2M2btxYrD/99NPF+kMPPVSs1zv/IRu27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBMfZW6De9eaLFy9uavlbtmwp1gcHB5tafkm921xfd911DS9706ZNxfoNN9zQ8LIlaceOHU3NP96wZQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDjO3gLHjh0r1usNa9ysSZMm1awtX768qWXPnz+/WL/55psbXvYnn3xSrF944YUNL1uSZs2a1dT8403dLbvt52wfsr1txLQptl+1/UH1OLm9bQJo1lh2438naeG3pj0o6fWIuEzS69VrAD2sbtgj4g1Jh781eZGkldXzlZKaOx8UQNs1+p29PyKGqucHJPXXeqPtZZKWNfg5AFqk6R/oIiJKAzZGxICkAWn8DuwInAkaPfR20PZ0SaoeD7WuJQDt0GjY10laUj1fIuml1rQDoF3q7sbbfkHSfElTbe+X9CtJj0tabXuppL2SftrOJrO7+OKLi/VVq1bVrNUbA72bLrroorYu/7XXXmvr8s80dcMeEXfWKN3U4l4AtBGnywJJEHYgCcIOJEHYgSQIO5AEl7ieAeoNPTx37twOddJb9u3bV6zXuwV3NmzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJjrOfAa688spi/eDBgzVrM2fObHU7p2XXrl01azt37izOe+uttxbra9euLdbr3ao6G7bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5CEIzo3SAsjwrRHf3/N0bd01113Fee94oorivXPP/+8WF+9enWxvn///pq1AwcOFOcdHBws1r/44oti/dprr61ZO3LkSHHeM1lEeLTpbNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmOs6Nr+vr6ivUPP/ywWJ80aVKxftVVV9Wsffzxx8V5z2QNH2e3/ZztQ7a3jZj2qO1B2+9Uf7e0slkArTeW3fjfSVo4yvQnI2J29fdya9sC0Gp1wx4Rb0g63IFeALRRMz/Q3Wf7vWo3f3KtN9leZnuz7c1NfBaAJjUa9t9IulTSbElDkn5d640RMRARcyJiToOfBaAFGgp7RByMiJMRcUrSbyXlHEYUOIM0FHbb00e8/ImkbbXeC6A31L1vvO0XJM2XNNX2fkm/kjTf9mxJIekjST9vY48Ypy655JJi/dxzzy3Wjx8/XqyfPHnytHsaz+qGPSLuHGXys23oBUAbcboskARhB5Ig7EAShB1IgrADSTBkM9qqdJnpI488Upz3nHPOKdbffvvtYv3o0aPFejZs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCW4ljabMmzevWH/llVdq1updwvr1118X6zfddFOxvnHjxmJ9vGLIZiA5wg4kQdiBJAg7kARhB5Ig7EAShB1IguvZx4EpU6bUrE2YMKE47x133FGsL168uFi//vrri/WJEycW6yUbNmwo1g8fZgjC08GWHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dh7B8yePbtYnzp1arG+YMGCYv3ee++tWevr6yvO227Hjh2rWXv44YeL8z7zzDPF+ldffdVQT1nV3bLbnml7g+0dtrfb/mU1fYrtV21/UD1Obn+7ABo1lt34E5Luj4hZkv5J0i9sz5L0oKTXI+IySa9XrwH0qLphj4ihiHirev6lpJ2SZkhaJGll9baVksrnVQLoqtP6zm77B5J+JOlPkvojYqgqHZDUX2OeZZKWNd4igFYY86/xts+X9KKk5RFxZGQthu9aOerNJCNiICLmRMScpjoF0JQxhd329zQc9OcjYk01+aDt6VV9uqRD7WkRQCvU3Y23bUnPStoZEU+MKK2TtETS49XjS23psENWrFhRrN9zzz0NL3v69OnFer1bKveyXbt2FeulS2Tff//9VreDgrF8Z/9nSXdJ2mr7nWraCg2HfLXtpZL2Svppe1oE0Ap1wx4RGyWNetN5SeW79APoGZwuCyRB2IEkCDuQBGEHkiDsQBJc4lq5/PLLi/VLL720Q5101tatW4v1J554oljfs2dPsc6x9N7Blh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkvDwTWY69GF25z7sNE2bNq1Y37JlS83ajBkzivMO3xKgtnr/DYaGhor1tWvX1qwNDAwU5929e3exfvTo0WIdvSciRv0fji07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBcXZgnOE4O5AcYQeSIOxAEoQdSIKwA0kQdiAJwg4kUTfstmfa3mB7h+3ttn9ZTX/U9qDtd6q/W9rfLoBG1T2pxvZ0SdMj4i3bfZK2SFqs4fHY/xIR/zXmD+OkGqDtap1UM5bx2YckDVXPv7S9U1L51iwAes5pfWe3/QNJP5L0p2rSfbbfs/2c7ck15llme7PtzU11CqApYz433vb5kv4o6T8iYo3tfkmfSgpJ/67hXf1/q7MMduOBNqu1Gz+msNv+nqT1kn4fEd8Z6a/a4q+PiL+vsxzCDrRZwxfCePjWqM9K2jky6NUPd9/4iaRtzTYJoH3G8mv8PEn/J2mrpFPV5BWS7pQ0W8O78R9J+nn1Y15pWWzZgTZraje+VQg70H5czw4kR9iBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUii7g0nW+xTSXtHvJ5aTetFvdpbr/Yl0VujWtnb39UqdPR69u98uL05IuZ0rYGCXu2tV/uS6K1RneqN3XggCcIOJNHtsA90+fNLerW3Xu1LordGdaS3rn5nB9A53d6yA+gQwg4k0ZWw215o+8+2d9t+sBs91GL7I9tbq2Gouzo+XTWG3iHb20ZMm2L7VdsfVI+jjrHXpd56YhjvwjDjXV133R7+vOPf2W1PkPS+pJsl7Ze0SdKdEbGjo43UYPsjSXMiousnYNi+TtJfJP33N0Nr2f5PSYcj4vHqH8rJEfFAj/T2qE5zGO829VZrmPF/VRfXXSuHP29EN7bscyXtjog9EXFc0ipJi7rQR8+LiDckHf7W5EWSVlbPV2r4f5aOq9FbT4iIoYh4q3r+paRvhhnv6ror9NUR3Qj7DEn7Rrzer94a7z0k/cH2FtvLut3MKPpHDLN1QFJ/N5sZRd1hvDvpW8OM98y6a2T482bxA913zYuIf5T0L5J+Ue2u9qQY/g7WS8dOfyPpUg2PATgk6dfdbKYaZvxFScsj4sjIWjfX3Sh9dWS9dSPsg5Jmjnj9/WpaT4iIwerxkKS1Gv7a0UsOfjOCbvV4qMv9/FVEHIyIkxFxStJv1cV1Vw0z/qKk5yNiTTW56+tutL46td66EfZNki6z/UPbEyX9TNK6LvTxHbbPq344ke3zJP1YvTcU9TpJS6rnSyS91MVe/kavDONda5hxdXnddX3484jo+J+kWzT8i/yHkh7uRg81+rpE0rvV3/Zu9ybpBQ3v1n2t4d82lkq6UNLrkj6Q9JqkKT3U2/9oeGjv9zQcrOld6m2ehnfR35P0TvV3S7fXXaGvjqw3TpcFkuAHOiAJwg4kQdiBJAg7kARhB5Ig7EAShB1I4v8BrqhNNNu+F1MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPyklEQVR4nO3de4hdVZbH8d+y8n4aDQmVGIwRFYOJ9pCIMDLJ0KSjomhQmgRs0oxMGmmlg/PHiPNHC0NDGMYe5q+WNEqnh4xtg4ohiNGWJhkRYyqSiTHaSSZGkpDHxDzN+7Hmj3vSU6119i7v69yq9f1AUbfOurvuqmt+nnPvvudsc3cBGPyuqboBAO1B2IEgCDsQBGEHgiDsQBBD2vlgZsZb/0CLubv1tb2hPbuZ3WdmfzKzXWb2bCO/C0BrWb3z7GbWJWmHpAWS9knaJGmJu29PjGHPDrRYK/bsd0va5e673f2CpN9JeriB3weghRoJ+1RJe3v9vK/Y9hfMbJmZ9ZhZTwOPBaBBLX+Dzt1XSlopcRgPVKmRPft+SdN6/XxDsQ1AB2ok7Jsk3WJmN5nZMEmLJa1pTlsAmq3uw3h3v2RmT0laJ6lL0svu/mnTOgPQVHVPvdX1YLxmB1quJR+qATBwEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQRFuXbEZ9zPq8WOifjR49urQ2YsSIhh47d/Xhrq6uZD31+GfPnk2OPX78eLJ+6dKlZL2dV04eCNizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQzLO3QW6efMKECcn6/fffn6zPmTOntDZ//vzk2HHjxiXrFy5cSNZPnDiRrG/atKm0tmvXruTY/fv3J+tbt25N1k+ePFla++qrr5JjB+McfkNhN7M9kk5JuizpkruX/6sDUKlm7Nn/1t2PNOH3AGghXrMDQTQadpf0jpltNrNlfd3BzJaZWY+Z9TT4WAAa0Ohh/L3uvt/MJkl618w+d/cNve/g7islrZQkMxt472oAg0RDe3Z33198PyzpDUl3N6MpAM1Xd9jNbLSZjb16W9IPJG1rVmMAmsvqnS80sxmq7c2l2suB/3T3X2TGDMrD+Nw8+pQpU5L1Rx99NFmfO3dusj5r1qzS2tSpU5NjhwxJv5LL1c+fP5+sp+azjxxJT+Lk6nv37k3W161bV1pbv359cuzp06eT9cuXLyfrVXL3Pv9B1v2a3d13S7qz7o4AtBVTb0AQhB0IgrADQRB2IAjCDgTBKa5NcM016f9nXn/99cn6TTfdlKxfuXIlWf/6669La7mpsdy0Ye5UzzNnziTr48ePL63lTq/Nnfp77ty5uuvDhw9Pjk09pwMVe3YgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIJ59jY4ePBgsv7qq68m67n56NQprmPHjk2OHTNmTLJ+7NixZP3UqVPJ+oMPPlhay51+m5vjP3r0aLKeOkU2N0c/EC8VncOeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJ69CXLnm+fmg3PnTo8cOTJZz11SOSV3PnvusZcsWZKsDx06tO7Hzi0H/fnnnyfrqctYnz17NjmWeXYAAxZhB4Ig7EAQhB0IgrADQRB2IAjCDgTBPHsT5OZkc+dl5+bpc8sDd3V1ldZuvfXW5NgZM2Yk6wsXLkzWb7vttmR91KhRpbXc3/XBBx8k6x9++GGynppnz/03GYyye3Yze9nMDpvZtl7brjOzd81sZ/E9fTV/AJXrz2H8byTd941tz0p6z91vkfRe8TOADpYNu7tvkPTNz3s+LGlVcXuVpEea3BeAJqv3Nftkdz9Q3D4oaXLZHc1smaRldT4OgCZp+A06d3czK32Hyt1XSlopSan7AWiteqfeDplZtyQV3w83ryUArVBv2NdIWlrcXirpzea0A6BVsofxZvaKpPmSJprZPkk/l7RC0u/N7AlJX0r6YSubjG7KlCnJ+uLFi0trDz30UHLs9OnTk/XUHL4kjR49OllPfYZg7dq1ybEbN25M1nPnu0ecS0/Jht3dy65O8P0m9wKghfi4LBAEYQeCIOxAEIQdCIKwA0Fwimsb5C6ZnFpyWZKefPLJZH3evHmlte7u7uTYESNGJOtDhjT2TyS1NPLNN9+cHDt37txkfefOncl66jLW58+fT44djNizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQzLO3QW6u+p577knWp02blqwPGzastHbhwoXk2NxnAHKXe87VU4+fu8x17u+eOHFisr5ixYrSWm7J5tzfNRCxZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIJhn7wDbtm1L1keOHJms7969u7R2+vTp5NjUssa53y1JkyZNStZnz55dWnvssceSY8eOHZusL1iwIFlPXYp69erVybHMswMYsAg7EARhB4Ig7EAQhB0IgrADQRB2IAjm2dsgN2e7efPmZD03D5+Suz76xYsX6/7dknTNNen9xZ133llay53HP2PGjGR9+PDhyXqqN3dPjh2Msnt2M3vZzA6b2bZe2543s/1mtqX4eqC1bQJoVH8O438j6b4+tv+bu99VfL3V3LYANFs27O6+QdLRNvQCoIUaeYPuKTPbWhzmTyi7k5ktM7MeM+tp4LEANKjesP9K0s2S7pJ0QNILZXd095XuPsfd59T5WACaoK6wu/shd7/s7lck/VrS3c1tC0Cz1RV2M+u9DvAiSfXPDQFoi+w8u5m9Imm+pIlmtk/SzyXNN7O7JLmkPZJ+0sIeB7wrV64k67lru6fWOK9a7m87ePBgaS33d+Xm8M+cOZOsnzhxorSW63swyobd3Zf0sfmlFvQCoIX4uCwQBGEHgiDsQBCEHQiCsANBcIprBxjI00Cp5aIlad68eaW16dOnJ8fmpiR37NiRrKcugz2Qn/N6sWcHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSDCzLMPHTo0Wc9d7jl16eHBfFniESNGJOtPP/10sv7MM8+U1saPH58ce+jQoWT9/fffT9Z37txZWhuMSzLnsGcHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAGzTz7kCHpP2XixInJ+rFjx5J1Myut5ebZc/XcnG8j517nnpfcXPcLL5Qu9iNJWrRoUbI+cuTI0lpuOemNGzcm6y+++GKynrqUdETs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCGvnudhm1tCDpZbwTc3nStKUKVPq/t2SNG7cuLrH5q5/nlt6ODf+2muvLa3NnDkzOXb58uXJ+qxZs5L1Rq4TsH79+uTYJUv6WkD4/x05ciRZj8rd+/xQSHbPbmbTzOyPZrbdzD41s58V268zs3fNbGfxfUKzmwbQPP05jL8k6R/cfaakeyT91MxmSnpW0nvufouk94qfAXSobNjd/YC7f1zcPiXpM0lTJT0saVVxt1WSHmlVkwAa950+G29m0yV9T9JGSZPd/UBROihpcsmYZZKW1d8igGbo97vxZjZG0muSlrv7yd41r73L1+ebb+6+0t3nuPuchjoF0JB+hd3MhqoW9NXu/nqx+ZCZdRf1bkmHW9MigGbIHsZb7dzOlyR95u6/7FVaI2mppBXF9zdb0mEvqVM9u7q6kmNHjRqVrN94443J+sKFC+see+7cuWQ911tqak2SJk2aVFdNyk9Z5qYVL168mKy/9dZbpbXHH388Ofbs2bPJOr6b/rxm/2tJP5L0iZltKbY9p1rIf29mT0j6UtIPW9MigGbIht3d35dUduWG7ze3HQCtwsdlgSAIOxAEYQeCIOxAEIQdCGLQXEo6d1niG264IVm/4447kvXUHH93d3dy7IQJ6RMChw8fnqyPGTMmWR82bFhpLXcp6dxlqr/44otkPXeK7Ntvv133Y6O52LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCDZp49d7nljz76KFnPLZs8e/bs0tr27duTY+fNm5es5+bZc/PRx48fL6298cYbybHvvPNOsr5hw4ZkPbfUdTsvVY409uxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EMSAWrK5wcdO1nPXnU/Vc+fK33777cl6blnkrVu3Jus9PT2ltaNHjybH5q77joGn7iWbAQwOhB0IgrADQRB2IAjCDgRB2IEgCDsQRHae3cymSfqtpMmSXNJKd/93M3te0t9L+t/irs+5e/li3Kp2nh2IomyevT9h75bU7e4fm9lYSZslPaLaeuxfu/u/9rcJwg60XlnY+7M++wFJB4rbp8zsM0lTm9segFb7Tq/ZzWy6pO9J2lhsesrMtprZy2bW5xpHZrbMzHrMrPwznQBart+fjTezMZLWS/qFu79uZpMlHVHtdfw/q3ao/3eZ38FhPNBidb9mlyQzGyppraR17v7LPurTJa119+TqiIQdaL26T4Sx2uliL0n6rHfQizfurlokaVujTQJonf68G3+vpP+S9Imkq9c0fk7SEkl3qXYYv0fST4o381K/iz070GINHcY3C2EHWo/z2YHgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0FkLzjZZEckfdnr54nFtk7Uqb11al8SvdWrmb3dWFZo6/ns33pwsx53n1NZAwmd2lun9iXRW73a1RuH8UAQhB0Iouqwr6z48VM6tbdO7Uuit3q1pbdKX7MDaJ+q9+wA2oSwA0FUEnYzu8/M/mRmu8zs2Sp6KGNme8zsEzPbUvX6dMUaeofNbFuvbdeZ2btmtrP43ucaexX19ryZ7S+euy1m9kBFvU0zsz+a2XYz+9TMflZsr/S5S/TVluet7a/ZzaxL0g5JCyTtk7RJ0hJ3397WRkqY2R5Jc9y98g9gmNnfSPpa0m+vLq1lZv8i6ai7ryj+RznB3f+xQ3p7Xt9xGe8W9Va2zPiPVeFz18zlz+tRxZ79bkm73H23u1+Q9DtJD1fQR8dz9w2Sjn5j88OSVhW3V6n2j6XtSnrrCO5+wN0/Lm6fknR1mfFKn7tEX21RRdinStrb6+d96qz13l3SO2a22cyWVd1MHyb3WmbroKTJVTbTh+wy3u30jWXGO+a5q2f580bxBt233evufyXpfkk/LQ5XO5LXXoN10tzpryTdrNoagAckvVBlM8Uy469JWu7uJ3vXqnzu+uirLc9bFWHfL2lar59vKLZ1BHffX3w/LOkN1V52dJJDV1fQLb4frrifP3P3Q+5+2d2vSPq1KnzuimXGX5O02t1fLzZX/tz11Ve7nrcqwr5J0i1mdpOZDZO0WNKaCvr4FjMbXbxxIjMbLekH6rylqNdIWlrcXirpzQp7+Qudsox32TLjqvi5q3z5c3dv+5ekB1R7R/5/JP1TFT2U9DVD0n8XX59W3ZukV1Q7rLuo2nsbT0i6XtJ7knZK+oOk6zqot/9QbWnvraoFq7ui3u5V7RB9q6QtxdcDVT93ib7a8rzxcVkgCN6gA4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEg/g8YaS3ZfBUBuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(trainloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    print(inputs.shape)\n",
    "    imshow(torchvision.utils.make_grid(inputs).numpy())     \n",
    "    \n",
    "    inputs=torch.flatten(inputs)\n",
    "        # zero the parameter gradients\n",
    "        # forward + backward + optimize\n",
    "    \n",
    "    inputs_noise=GaussianNoise(0.2)(inputs).reshape((1,1,28,28))\n",
    "    imshow(torchvision.utils.make_grid(inputs_noise).detach().numpy())\n",
    "    \n",
    "    outputs = model(inputs).reshape((1, 1, 28, 28))\n",
    "    \n",
    "    imshow(torchvision.utils.make_grid(outputs).detach().numpy())     \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PU-Learning via matrix completion and convex optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pu_learning(x, y, P, k = 7, alpha = 0.2, gamma = 0.3, maxiter=1000):\n",
    "    Fd = x.shape[1]\n",
    "    Ft = y.shape[1]\n",
    "    Nd = x.shape[0]\n",
    "    Nt = y.shape[0]\n",
    "    \n",
    "    #Number of variables\n",
    "    N_variables = Fd * k + Ft * k\n",
    "    \n",
    "    print(\"Number of variables:\", N_variables)\n",
    "    #Because scipy's minimize needs a (n,) array of variables\n",
    "    mat_compo = {}\n",
    "    compo_mat = []\n",
    "    p=0\n",
    "\n",
    "    for c in ['H', 'W']:\n",
    "        for i in range(Fd if c=='H' else Ft):\n",
    "            for j in range(k):\n",
    "                mat_compo[(c, i, j)] = p\n",
    "                compo_mat.append((c, i, j))\n",
    "                p += 1\n",
    "    \n",
    "    print(\"Finding positive and negative examples...\")\n",
    "    Ipos = [(i,j) for i in range(Nd) for j in range(Nt) if P[i,j]==1.0]\n",
    "    Ineg = [(i,j) for i in range(Nd) for j in range(Nt) if P[i,j]==0.0]\n",
    "    I = Ipos + Ineg\n",
    "    \n",
    "    print(\"Number of positive examples:\", len(Ipos))\n",
    "    print(\"Number of negative/unlabelled examples:\", len(Ineg))\n",
    "    \n",
    "    def objective(z):\n",
    "        res=0\n",
    "    \n",
    "        H = np.zeros((Fd,k), dtype=float)\n",
    "        W = np.zeros((Ft,k), dtype=float)\n",
    "    \n",
    "        for i in range(Fd):\n",
    "            for j in range(k):\n",
    "                H[i,j]=z[mat_compo[('H', i, j)]]\n",
    "            \n",
    "        for i in range(Ft):\n",
    "            for j in range(k):\n",
    "                W[i,j]=z[mat_compo[('W', i, j)]]\n",
    "         \n",
    "        for (i,j) in Ipos:\n",
    "            res += (P[i,j]- np.dot(np.dot(x[i,:], (H @ np.transpose(W))), y[j,:]))**2\n",
    "        for (i,j) in Ineg:\n",
    "            res += alpha*(P[i,j]- np.dot(np.dot(x[i,:], (H @ np.transpose(W))), y[j,:]))**2\n",
    "    \n",
    "        Sreg = gamma/2 * (np.linalg.norm(H) + np.linalg.norm(W))\n",
    "    \n",
    "        res += Sreg\n",
    "    \n",
    "        return(res)\n",
    "    \n",
    "    print(\"Going to minimize... Maximum number of iterations:\", maxiter)\n",
    "    res=minimize(objective, x0 = np.random.randn(N_variables), options={'maxiter':maxiter, 'disp':'True'})\n",
    "    \n",
    "    print(\"\\n\\nSolved.\")\n",
    "    \n",
    "    z=res['x']\n",
    "    H = np.zeros((Fd,k), dtype=float)\n",
    "    W = np.zeros((Ft,k), dtype=float)\n",
    "    \n",
    "    for i in range(Fd):\n",
    "        for j in range(k):\n",
    "            H[i,j]=z[mat_compo[('H', i, j)]]\n",
    "            \n",
    "    for i in range(Ft):\n",
    "        for j in range(k):\n",
    "            W[i,j]=z[mat_compo[('W', i, j)]]\n",
    "    \n",
    "    print(\"Now computing Z=HW^T, then will compute S...\")\n",
    "    Z = H @ np.transpose(W)\n",
    "    \n",
    "    S = np.zeros((Nd, Nt))\n",
    "    for i,j in I:\n",
    "        S[i,j] = np.dot(np.dot(x[i,:], Z), y[:,j])\n",
    "    \n",
    "    return(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PU Learning\n",
    "\n",
    "k = 7\n",
    "Fd = 20\n",
    "Ft = 20\n",
    "\n",
    "#Number of variables\n",
    "N_variables = Fd * k + Ft * k\n",
    "\n",
    "#Because scipy's minimize needs a (n,) array of variables\n",
    "mat_compo = {}\n",
    "compo_mat = []\n",
    "p=0\n",
    "\n",
    "for c in ['H', 'W']:\n",
    "    for i in range(Fd if c=='H' else Ft):\n",
    "        for j in range(k):\n",
    "            mat_compo[(c, i, j)] = p\n",
    "            compo_mat.append((c, i, j))\n",
    "            p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nd = 20\n",
    "Nt = 20\n",
    "\n",
    "p = np.eye(20, dtype=float)\n",
    "x = np.random.randn(Nd,Fd)\n",
    "y = np.random.randn(Nt,Ft)\n",
    "\n",
    "alpha = 0.2\n",
    "gamma = 0.3\n",
    "\n",
    "Ipos = [(i,i) for i in range(min(Nd,Nt))]\n",
    "Ineg = [(i,j) for i in range(Nd) for j in range(Nt) if (i,j) not in Ipos]\n",
    "I = Ipos + Ineg\n",
    "\n",
    "def objective(z):\n",
    "    res=0\n",
    "    \n",
    "    H = np.zeros((Fd,k), dtype=float)\n",
    "    W = np.zeros((Ft,k), dtype=float)\n",
    "    \n",
    "    for i in range(Fd):\n",
    "        for j in range(k):\n",
    "            H[i,j]=z[mat_compo[('H', i, j)]]\n",
    "            \n",
    "    for i in range(Ft):\n",
    "        for j in range(k):\n",
    "            W[i,j]=z[mat_compo[('W', i, j)]]\n",
    "         \n",
    "    for (i,j) in Ipos:\n",
    "        res += (p[i,j]- np.dot(np.dot(x[i,:], (H @ np.transpose(W))), y[:,j]))**2\n",
    "    for (i,j) in Ineg:\n",
    "        res += alpha*(p[i,j]- np.dot(np.dot(x[i,:], (H @ np.transpose(W))), y[:,j]))**2\n",
    "    \n",
    "    Sreg = gamma/2 * (np.linalg.norm(H) + np.linalg.norm(W))\n",
    "    \n",
    "    res += Sreg\n",
    "    \n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 6.829665\n",
      "         Iterations: 1000\n",
      "         Function evaluations: 284538\n",
      "         Gradient evaluations: 1009\n"
     ]
    }
   ],
   "source": [
    "res = minimize(objective,x0 = np.random.randn(N_variables), options={'maxiter':1000, 'disp':'True'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2156256971064746\n",
      "0.32101247399922694\n",
      "-0.08885838184022438\n",
      "0.08233132094469015\n",
      "0.062120094941989355\n",
      "-0.3769398966190506\n",
      "-0.16007070675968857\n",
      "-0.1175141503312301\n",
      "0.3132671197931596\n",
      "0.12212999909888365\n",
      "0.18886774771029252\n",
      "0.1406524958251719\n",
      "0.34237874607068397\n",
      "-0.2840154424597365\n",
      "0.04800438015653148\n",
      "-0.11207551752224493\n",
      "0.03384893586862922\n",
      "0.27059663352276064\n",
      "-0.48687662827390343\n",
      "0.19229498628662084\n",
      "-0.2630780666249034\n",
      "0.11850204407581913\n",
      "0.1061514311398693\n",
      "-0.1488636535906391\n",
      "0.2101892946283354\n",
      "-0.08611401275830777\n",
      "0.3248914544289978\n",
      "0.22064895828783526\n",
      "-0.21372587896585798\n",
      "0.28920854715348643\n",
      "0.2303915437191929\n",
      "0.43439703814341285\n",
      "-0.1169274019061948\n",
      "0.3577067468410794\n",
      "0.18783391568892388\n",
      "0.045509432547769624\n",
      "-0.2095365695838818\n",
      "-0.14464879335870995\n",
      "0.32321428325492335\n",
      "-0.24325847533612158\n",
      "-0.1266791676258012\n",
      "0.4080895645803141\n",
      "0.039041491129598496\n",
      "0.009295704832545992\n",
      "-0.34240381593296176\n",
      "-0.059335308473098064\n",
      "-0.042737677874143565\n",
      "0.2350307312628195\n",
      "0.020343417516329065\n",
      "0.08741020561189941\n",
      "-0.20714371932758407\n",
      "0.06017643476629825\n",
      "0.12146295965254293\n",
      "-0.21721329901272735\n",
      "-0.39402268954614283\n",
      "0.40856098545937314\n",
      "-0.1397487803420088\n",
      "-0.0943856116299812\n",
      "0.08962819803646627\n",
      "-0.13941016581082954\n",
      "-0.25712302294731143\n",
      "0.6068882519759633\n",
      "0.13940391442309927\n",
      "0.00978498176056436\n",
      "0.017476620834715698\n",
      "-0.39193123189533\n",
      "0.05599220495116169\n",
      "-0.13934435014926005\n",
      "0.34727211861355284\n",
      "0.2703174430903042\n",
      "-0.17670747319705232\n",
      "0.04494868324274062\n",
      "0.1513182578408119\n",
      "-0.2614322148203796\n",
      "0.004160865965042504\n",
      "0.07934092495863748\n",
      "0.08358124674334837\n",
      "0.11750505819648614\n",
      "0.3921577474954172\n",
      "-0.24177659465368945\n",
      "-0.2805306537099777\n",
      "0.35833859442937727\n",
      "-0.42930938466753354\n",
      "0.12143806899808586\n",
      "0.014038607979863268\n",
      "-0.2276867665679331\n",
      "-0.012798702535273349\n",
      "-0.2107038537708888\n",
      "0.06310262559897968\n",
      "-0.14400745671626872\n",
      "0.225085768815943\n",
      "-0.32014522709334514\n",
      "-0.2620225437400775\n",
      "0.005213717303562043\n",
      "0.16250957336138247\n",
      "0.06331896309049487\n",
      "-0.1582144626572694\n",
      "0.03139373138862231\n",
      "0.623996365847286\n",
      "-0.2960814932530168\n",
      "-0.13682852587302616\n",
      "0.0797227714888547\n",
      "-0.15912874159357604\n",
      "-0.4148031243719279\n",
      "0.1282024936380529\n",
      "-0.23998991544754072\n",
      "0.20662424688679268\n",
      "0.2392616057872741\n",
      "-0.2520104941072222\n",
      "-0.08648562380629338\n",
      "-0.04370167181007828\n",
      "-0.21588690785862014\n",
      "0.17246886087458826\n",
      "-0.057763914384075965\n",
      "-0.3558440777817268\n",
      "0.19627440069370666\n",
      "0.005859764802829848\n",
      "0.15749440509269286\n",
      "0.35593169994935736\n",
      "-0.11310238447958493\n",
      "-0.33890771114372087\n",
      "0.08278882560691403\n",
      "-0.22032181040486534\n",
      "-0.2854933708958344\n",
      "0.1852701796285125\n",
      "0.22989581878754703\n",
      "-0.03237624631339636\n",
      "0.1284048835568754\n",
      "0.1534494057708935\n",
      "0.08785461819671311\n",
      "-0.1670092610604318\n",
      "-0.02854383661825194\n",
      "0.5071262436795254\n",
      "-0.16983984656071738\n",
      "-0.08223009426661355\n",
      "-0.35275452885184055\n",
      "0.009247167007078005\n",
      "-0.42188838582189253\n",
      "0.07188960428143948\n",
      "-0.3195989511125301\n",
      "0.18557237836377555\n",
      "-0.2722449976514071\n",
      "-0.1489999773432108\n",
      "-0.04739275851427904\n",
      "-0.19744653356129435\n",
      "-0.08033434791496197\n",
      "0.295427049571264\n",
      "0.20376622308916592\n",
      "-0.15228878978462956\n",
      "0.2750948375850163\n",
      "0.029646380413555655\n",
      "-0.3386084052171674\n",
      "-0.09949696114970111\n",
      "0.31583329600244314\n",
      "-0.09982727953794669\n",
      "0.03558127325156643\n",
      "0.11147481960563849\n",
      "-0.1356272898003691\n",
      "0.096637360467501\n",
      "0.20800834671392202\n",
      "0.009413826063298214\n",
      "0.10131400348300279\n",
      "-0.15773718193625216\n",
      "-0.12173907053317858\n",
      "-0.06084618905147682\n",
      "0.19424944273869288\n",
      "0.5941659905295124\n",
      "0.08955338278738433\n",
      "-0.3602397986504336\n",
      "-0.3579514889996744\n",
      "-0.29588911925795214\n",
      "0.3048392661323286\n",
      "0.2521828599067393\n",
      "-0.05464149510538652\n",
      "-0.36373186585508455\n",
      "0.003752614761238046\n",
      "-0.3885665576444708\n",
      "-0.1878380608196771\n",
      "-0.27661149327942536\n",
      "0.02049427061271729\n",
      "0.3044705433655105\n",
      "0.12026889484961567\n",
      "0.02043301743626499\n",
      "0.027778710554051213\n",
      "-0.14094716990970896\n",
      "-0.18761951470678898\n",
      "0.36849041760329493\n",
      "0.11609600176244975\n",
      "-0.30177231316173136\n",
      "-0.11726451037989766\n",
      "0.12247564488527297\n",
      "-0.2563282258125359\n",
      "0.24745934862994995\n",
      "0.03969417151630705\n",
      "-0.20730920365018923\n",
      "0.13455610783378535\n",
      "-0.26574813633882266\n",
      "-0.14689826123413813\n",
      "0.08753369968197167\n",
      "0.29476819649488994\n",
      "-0.24577498444599719\n",
      "0.136399351213393\n",
      "-0.33822548144125497\n",
      "0.05810949922673109\n",
      "-0.14371473873246068\n",
      "0.39366401922068395\n",
      "-0.3966730063998505\n",
      "-0.12657413161091643\n",
      "-0.17681723883996842\n",
      "0.19411878718990097\n",
      "0.3353345432823114\n",
      "0.014294239372396197\n",
      "-0.11535260249137062\n",
      "-0.007303652203645074\n",
      "-0.23253269778900054\n",
      "0.1896183551402384\n",
      "-0.06436482663524504\n",
      "-0.14511312241586688\n",
      "0.11860516635906816\n",
      "-0.23735651398338348\n",
      "0.5137022277496277\n",
      "0.03355226189787286\n",
      "0.3196951405187839\n",
      "0.11304601496539818\n",
      "0.1499063921418184\n",
      "0.359236887434552\n",
      "0.3974115589820771\n",
      "-0.05228627567552788\n",
      "0.13602420957228695\n",
      "0.2062851165448577\n",
      "0.08569536273132831\n",
      "0.3359459582883499\n",
      "-0.19731062291008003\n",
      "0.19624375842253147\n",
      "0.20933407008102692\n",
      "-0.20152321977075044\n",
      "-0.12237507983091073\n",
      "-0.002591277509947809\n",
      "0.1551371854731254\n",
      "0.4615795005241847\n",
      "0.0025693498316562563\n",
      "0.21269824627851888\n",
      "0.02487559391624261\n",
      "0.4107691359982403\n",
      "-0.03679552691184748\n",
      "0.31712159808452345\n",
      "0.011970688705064042\n",
      "0.33308194041288824\n",
      "0.4460866107858103\n",
      "-0.1980396745795652\n",
      "0.27674332957249187\n",
      "0.05715199424254752\n",
      "0.22313608645846483\n",
      "-0.05315190951675816\n",
      "-0.08265692412006254\n",
      "-0.07159080700168832\n",
      "0.0070178109370160335\n",
      "-0.3285089543016538\n",
      "0.012693598220443386\n",
      "0.004838798550088515\n",
      "-0.5723851533074108\n",
      "0.03283461387355968\n",
      "-0.1716146832919876\n",
      "0.1303851899280749\n",
      "-0.06669526117481878\n",
      "-0.09803005352367944\n",
      "-0.24520816111378027\n",
      "-0.10510446974604695\n",
      "0.0464632828773586\n",
      "-0.16459568686984227\n",
      "-0.1300259398676554\n",
      "-0.22282333302768825\n",
      "0.1321698028449564\n",
      "0.2921929189191512\n",
      "0.1893340374261501\n",
      "-0.1332729668102819\n",
      "0.047877136671904234\n",
      "0.3290762770086457\n",
      "0.22993063686478976\n",
      "-0.5334835633733672\n",
      "0.2695979623600122\n",
      "0.14767182499636436\n",
      "0.055951806964040035\n",
      "0.24246464572173132\n",
      "-0.09169850566527471\n",
      "0.03294410987652904\n",
      "0.3378138068935207\n",
      "0.06814902604413892\n",
      "0.07682109450115931\n",
      "0.20200502281689886\n",
      "-0.05849478775982131\n",
      "0.1550112350328653\n",
      "0.23785028436433742\n",
      "0.589559830824979\n",
      "-0.21356454623506213\n",
      "-0.12913187838230206\n",
      "0.08163059049175633\n",
      "0.02803228679267882\n",
      "0.023371527953223503\n",
      "0.27426680378644014\n",
      "-0.1298840265477451\n",
      "-0.2674990458916525\n",
      "0.019455440120841272\n",
      "-0.364913971178368\n",
      "-0.10849756539600434\n",
      "0.17998224354220008\n",
      "-0.24198529418328443\n",
      "0.1504136677413892\n",
      "-0.3437769310301396\n",
      "-0.04359441615979387\n",
      "0.10149320048722818\n",
      "-0.16333178216816957\n",
      "0.08502639202924539\n",
      "0.3743457028224558\n",
      "0.431882904726105\n",
      "0.1425764461504919\n",
      "0.44663337123577235\n",
      "-0.16662064081404965\n",
      "0.15951035921486167\n",
      "-0.15306766145862105\n",
      "-0.06011100265874614\n",
      "-0.2782684272597868\n",
      "0.11069446316926518\n",
      "0.0003503254187689486\n",
      "0.09168009197297951\n",
      "-0.38995582785950245\n",
      "-0.25784092758840327\n",
      "-0.2621402664746654\n",
      "-0.2341916136944358\n",
      "-0.15063170977091078\n",
      "0.26982319293529655\n",
      "-0.3373482786296025\n",
      "0.1216055173014827\n",
      "-0.3975820531623352\n",
      "0.37442891572162906\n",
      "-0.018167226883474177\n",
      "0.12811429179753275\n",
      "0.06644191744893249\n",
      "-0.24941979599267888\n",
      "-0.04897630795847666\n",
      "0.12835472505885026\n",
      "0.035506524678362586\n",
      "0.23159412627862763\n",
      "-0.20098260503289778\n",
      "0.41113259973013955\n",
      "0.00757752906028436\n",
      "0.02199936868493456\n",
      "0.1578600781749694\n",
      "-0.02977991955203635\n",
      "0.03674444864664142\n",
      "-0.3318057346835045\n",
      "-0.3073572615307818\n",
      "-0.13456578466894797\n",
      "0.38764814633360123\n",
      "0.3216564463447149\n",
      "-0.09607734537770063\n",
      "0.2581059908521283\n",
      "0.04447636202187774\n",
      "-0.25743496773704316\n",
      "0.1262099607356721\n",
      "-0.1342079218438997\n",
      "-0.4738275075794275\n",
      "-0.1257611859212696\n",
      "-0.148916471595884\n",
      "0.06790057334155705\n",
      "0.14056884216207077\n",
      "-0.07243652562564587\n",
      "0.4982514230970061\n",
      "-0.34655855897658583\n",
      "-0.27765307614105056\n",
      "-0.10512014875542708\n",
      "-0.19905141327397557\n",
      "-0.024006150642597868\n",
      "0.022247967188228218\n",
      "-0.08221069182278498\n",
      "-0.07312933516945158\n",
      "-0.363523445255585\n",
      "0.11935978742865916\n",
      "0.05093536394034853\n",
      "-0.15290462093986734\n"
     ]
    }
   ],
   "source": [
    "z=res['x']\n",
    "H = np.zeros((Fd,k), dtype=float)\n",
    "W = np.zeros((Ft,k), dtype=float)\n",
    "    \n",
    "for i in range(Fd):\n",
    "    for j in range(k):\n",
    "        H[i,j]=z[mat_compo[('H', i, j)]]\n",
    "            \n",
    "for i in range(Ft):\n",
    "    for j in range(k):\n",
    "        W[i,j]=z[mat_compo[('W', i, j)]]\n",
    "\n",
    "H @ np.transpose(W)\n",
    "\n",
    "for i,j in Ineg:\n",
    "    print(np.dot(np.dot(x[i,:], (H @ np.transpose(W))), y[:,j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_graph(p, size=(100,100)):\n",
    "    return(np.array([[int(random.random() < p) for i in range(size[1])] for j in range(size[0])]))\n",
    "\n",
    "def random_undirected_graph(p, size=(100,100)):\n",
    "    graph = random_graph(p, size=size)\n",
    "    graph[np.arange(size[0]),np.arange(size[1])]=0 #nullify the diagonal\n",
    "    graph = np.maximum(graph, graph.T) #make it symmetric\n",
    "    \n",
    "    return(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_graph_with_fixed_components(p, nodes_per_component=[50,50]):\n",
    "    nodes_per_component = np.array(nodes_per_component)\n",
    "    n_nodes = nodes_per_component.sum()\n",
    "    n_cmp = nodes_per_component.shape[0]\n",
    "    \n",
    "    graph = np.zeros((n_nodes, n_nodes))\n",
    "    nodes = np.arange(n_nodes)\n",
    "    np.random.shuffle(nodes)\n",
    "    \n",
    "    cmp_nodes = []\n",
    "    acc=0\n",
    "    \n",
    "    for i in range(n_cmp):\n",
    "        cmp = nodes[acc:(acc+nodes_per_component[i])]\n",
    "        cmp_nodes.append(cmp)\n",
    "        acc += nodes_per_component[i]\n",
    "        \n",
    "        size = cmp.shape[0]\n",
    "        submatrix=np.ix_(cmp,cmp)\n",
    "\n",
    "        graph[submatrix] = random_undirected_graph(p, (size,size))\n",
    "        \n",
    "    return(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbors(adj, i):\n",
    "    return (np.where(adj[i,:]==1)[0])\n",
    "\n",
    "def dfs(adj, i):\n",
    "    n = adj.shape[0] #number of nodes in the graph\n",
    "    visited = [False for k in range(n)]\n",
    "    \n",
    "    stack = [i]\n",
    "    \n",
    "    while(len(stack)>0):\n",
    "        k = stack.pop()\n",
    "        neighborhood = neighbors(adj, k)\n",
    "        visited[k] = True\n",
    "        \n",
    "        for n in neighborhood:\n",
    "            if not visited[n]:\n",
    "                stack.append(n)\n",
    "    \n",
    "    return(np.where(visited))\n",
    "\n",
    "def connected_components(adj):\n",
    "    n = adj.shape[0]\n",
    "    \n",
    "    visited = np.array([0 for k in range(n)])\n",
    "    s = np.sum(visited)\n",
    "    \n",
    "    comp=[]\n",
    "    \n",
    "    while s<n:\n",
    "        i = np.where(1-visited)[0][0]\n",
    "        \n",
    "        cmp = dfs(adj, i)\n",
    "        visited[cmp] = 1\n",
    "        s = np.sum(visited)\n",
    "        \n",
    "        comp.append(list(cmp[0]))\n",
    "    \n",
    "    return(np.array(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5001339285714286"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_rand_drugs = 784\n",
    "N_rand_targets = 1000\n",
    "\n",
    "density=0.5\n",
    "#generate random matrices in M({0,1})\n",
    "#1. a drug-drug network (drug similarities)\n",
    "#2. a protein-protein network (protein similarities)\n",
    "#3. a drug-protein network (drug-target known relationships)\n",
    "dd_net = random_graph_with_fixed_components(density, [196,196,196,196])\n",
    "pp_net = random_graph_with_fixed_components(density, [100 for i in range(10)])\n",
    "dp_net = random_graph(density,size=(N_rand_drugs,N_rand_targets))\n",
    "\n",
    "np.sum(dp_net)/(N_rand_drugs*N_rand_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18621147438567265"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.sum(dd_net))/(dd_net[0].shape[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_net[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the drug-drug network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdae(input_net, input_number, hidden_layers, n_epochs=100, batch_size=1, activation='sigmoid', last_activation='sigmoid'):\n",
    "    #hidden_layers=[500,200,100]\n",
    "    #input_numer=784\n",
    "    #  use gpu if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = SDAE(input_number, hidden_layers, activation=activation, last_activation=last_activation).to(device)\n",
    "\n",
    "    # create an optimizer object\n",
    "    # Adam optimizer with learning rate 1e-3\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # mean-squared error loss\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    summary(model, (input_number,))\n",
    "\n",
    "    train = torch.utils.data.TensorDataset(torch.Tensor(input_net), torch.Tensor(input_net))\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "        \n",
    "            inputs=torch.flatten(inputs)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % input_number == input_number-1: \n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / input_number))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "    return(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "      DropoutNoise-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 500]         392,500\n",
      "           Sigmoid-3                  [-1, 500]               0\n",
      "        BasicBlock-4                  [-1, 500]               0\n",
      "            Linear-5                  [-1, 200]         100,200\n",
      "           Sigmoid-6                  [-1, 200]               0\n",
      "        BasicBlock-7                  [-1, 200]               0\n",
      "            Linear-8                  [-1, 100]          20,100\n",
      "           Sigmoid-9                  [-1, 100]               0\n",
      "       BasicBlock-10                  [-1, 100]               0\n",
      "           Linear-11                  [-1, 200]          20,200\n",
      "          Sigmoid-12                  [-1, 200]               0\n",
      "       BasicBlock-13                  [-1, 200]               0\n",
      "           Linear-14                  [-1, 500]         100,500\n",
      "          Sigmoid-15                  [-1, 500]               0\n",
      "       BasicBlock-16                  [-1, 500]               0\n",
      "           Linear-17                  [-1, 784]         392,784\n",
      "          Sigmoid-18                  [-1, 784]               0\n",
      "       BasicBlock-19                  [-1, 784]               0\n",
      "================================================================\n",
      "Total params: 1,026,284\n",
      "Trainable params: 1,026,284\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 3.91\n",
      "Estimated Total Size (MB): 3.98\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "[1,   784] loss: 0.347\n",
      "[2,   784] loss: 0.317\n",
      "[3,   784] loss: 0.315\n",
      "[4,   784] loss: 0.254\n",
      "[5,   784] loss: 0.230\n",
      "[6,   784] loss: 0.228\n",
      "[7,   784] loss: 0.227\n",
      "[8,   784] loss: 0.227\n",
      "[9,   784] loss: 0.227\n",
      "[10,   784] loss: 0.226\n",
      "[11,   784] loss: 0.226\n",
      "[12,   784] loss: 0.226\n",
      "[13,   784] loss: 0.226\n",
      "[14,   784] loss: 0.226\n",
      "[15,   784] loss: 0.226\n",
      "[16,   784] loss: 0.226\n",
      "[17,   784] loss: 0.228\n",
      "[18,   784] loss: 0.226\n",
      "[19,   784] loss: 0.185\n",
      "[20,   784] loss: 0.141\n",
      "[21,   784] loss: 0.140\n",
      "[22,   784] loss: 0.139\n",
      "[23,   784] loss: 0.139\n",
      "[24,   784] loss: 0.139\n",
      "[25,   784] loss: 0.139\n",
      "[26,   784] loss: 0.139\n",
      "[27,   784] loss: 0.139\n",
      "[28,   784] loss: 0.139\n",
      "[29,   784] loss: 0.139\n",
      "[30,   784] loss: 0.139\n",
      "[31,   784] loss: 0.139\n",
      "[32,   784] loss: 0.139\n",
      "[33,   784] loss: 0.139\n",
      "[34,   784] loss: 0.139\n",
      "[35,   784] loss: 0.139\n",
      "[36,   784] loss: 0.139\n",
      "[37,   784] loss: 0.139\n",
      "[38,   784] loss: 0.139\n",
      "[39,   784] loss: 0.139\n",
      "[40,   784] loss: 0.139\n",
      "[41,   784] loss: 0.139\n",
      "[42,   784] loss: 0.139\n",
      "[43,   784] loss: 0.139\n",
      "[44,   784] loss: 0.139\n",
      "[45,   784] loss: 0.139\n",
      "[46,   784] loss: 0.139\n",
      "[47,   784] loss: 0.139\n",
      "[48,   784] loss: 0.139\n",
      "[49,   784] loss: 0.139\n",
      "[50,   784] loss: 0.139\n",
      "[51,   784] loss: 0.139\n",
      "[52,   784] loss: 0.139\n",
      "[53,   784] loss: 0.139\n",
      "[54,   784] loss: 0.139\n",
      "[55,   784] loss: 0.139\n",
      "[56,   784] loss: 0.139\n",
      "[57,   784] loss: 0.139\n",
      "[58,   784] loss: 0.139\n",
      "[59,   784] loss: 0.139\n",
      "[60,   784] loss: 0.139\n",
      "[61,   784] loss: 0.139\n",
      "[62,   784] loss: 0.139\n",
      "[63,   784] loss: 0.139\n",
      "[64,   784] loss: 0.139\n",
      "[65,   784] loss: 0.139\n",
      "[66,   784] loss: 0.139\n",
      "[67,   784] loss: 0.139\n",
      "[68,   784] loss: 0.139\n",
      "[69,   784] loss: 0.139\n",
      "[70,   784] loss: 0.139\n",
      "[71,   784] loss: 0.139\n",
      "[72,   784] loss: 0.139\n",
      "[73,   784] loss: 0.139\n",
      "[74,   784] loss: 0.139\n",
      "[75,   784] loss: 0.139\n",
      "[76,   784] loss: 0.139\n",
      "[77,   784] loss: 0.139\n",
      "[78,   784] loss: 0.139\n",
      "[79,   784] loss: 0.139\n",
      "[80,   784] loss: 0.139\n",
      "[81,   784] loss: 0.139\n",
      "[82,   784] loss: 0.139\n",
      "[83,   784] loss: 0.139\n",
      "[84,   784] loss: 0.139\n",
      "[85,   784] loss: 0.139\n",
      "[86,   784] loss: 0.139\n",
      "[87,   784] loss: 0.139\n",
      "[88,   784] loss: 0.139\n",
      "[89,   784] loss: 0.139\n",
      "[90,   784] loss: 0.139\n",
      "[91,   784] loss: 0.139\n",
      "[92,   784] loss: 0.139\n",
      "[93,   784] loss: 0.139\n",
      "[94,   784] loss: 0.139\n",
      "[95,   784] loss: 0.139\n",
      "[96,   784] loss: 0.139\n",
      "[97,   784] loss: 0.139\n",
      "[98,   784] loss: 0.139\n",
      "[99,   784] loss: 0.139\n",
      "[100,   784] loss: 0.139\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SDAE(\n",
       "   (encoder): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (noise): DropoutNoise()\n",
       "       (dense_layer): Linear(in_features=784, out_features=500, bias=True)\n",
       "       (activation): Sigmoid()\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (dense_layer): Linear(in_features=500, out_features=200, bias=True)\n",
       "       (activation): Sigmoid()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (dense_layer): Linear(in_features=200, out_features=100, bias=True)\n",
       "       (activation): Sigmoid()\n",
       "     )\n",
       "   )\n",
       "   (decoder): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (dense_layer): Linear(in_features=100, out_features=200, bias=True)\n",
       "       (activation): Sigmoid()\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (dense_layer): Linear(in_features=200, out_features=500, bias=True)\n",
       "       (activation): Sigmoid()\n",
       "     )\n",
       "     (2): BasicBlock(\n",
       "       (dense_layer): Linear(in_features=500, out_features=784, bias=True)\n",
       "       (activation): Sigmoid()\n",
       "     )\n",
       "   )\n",
       " ), <torch.utils.data.dataloader.DataLoader at 0x7f8eaeaf4f28>)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dd, train_loader_dd = sdae(ppmi_dd_net, 784, [500,200,100], n_epochs=100, batch_size=1, activation='sigmoid', last_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = random_undirected_graph(0.02, size=(100, 100))\n",
    "graph[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  3,  6,  8, 16, 20, 21, 31, 32, 38, 39, 41, 45, 55, 56,\n",
       "        60, 64, 65, 67, 68, 76, 81, 87, 95],\n",
       "       [ 2,  9, 18, 24, 27, 34, 35, 40, 48, 52, 59, 71, 75, 77, 78, 79,\n",
       "        80, 82, 83, 84, 85, 89, 93, 96, 97],\n",
       "       [ 4,  5,  7, 10, 22, 23, 28, 29, 44, 46, 47, 53, 54, 58, 62, 63,\n",
       "        66, 70, 73, 74, 86, 88, 90, 92, 99],\n",
       "       [11, 12, 13, 14, 15, 17, 19, 25, 26, 30, 33, 36, 37, 42, 43, 49,\n",
       "        50, 51, 57, 61, 69, 72, 91, 94, 98]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected_components(random_graph_with_fixed_components(0.2, [25,25,25,25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding evaluation with t-SNE visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_TSNE(embeddings,target):\n",
    "    tsne = TSNE(n_components=2, init='pca',\n",
    "                         random_state=0, perplexity=30)\n",
    "    data = tsne.fit_transform(embeddings)\n",
    "    #plt.figure(figsize=(12, 6))\n",
    "    plt.title(\"TSNE visualization of the embeddings\")\n",
    "    plt.scatter(data[:,0],data[:,1],c=target)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(train_loader, N, model, size_encoded=100):\n",
    "    trainiter = iter(train_loader)\n",
    "    embeddings = np.zeros((N, size_encoded))\n",
    "\n",
    "    for i,q in enumerate(trainiter):\n",
    "        embedded = model.encoder(q[0]).detach().numpy()\n",
    "        embeddings[i,:] = embedded.reshape((size_encoded,))\n",
    "    \n",
    "    return(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=get_embeddings(train_loader, N_rand_drugs, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmps = connected_components(dd_net)\n",
    "targets = [0 for i in range(N_rand_drugs)]\n",
    "\n",
    "for i, cmp in enumerate(cmps):\n",
    "    for n in cmp:\n",
    "        targets[n] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_TSNE(embeddings, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dngr_pipeline(network, N, hidden_layers, K=10, alpha=0.2, n_epochs=100, batch_size=1, activation='sigmoid', last_activation='sigmoid'):\n",
    "    ppmi_net = PPMI(PCO(network, K, alpha))\n",
    "    model, train_loader = sdae(ppmi_net, N, hidden_layers, n_epochs=n_epochs, batch_size=batch_size, activation=activation, last_activation=last_activation)\n",
    "    \n",
    "    print(\"[*] Visualizing an example's output...\")\n",
    "    trainiter = iter(train_loader)\n",
    "    inputs, _ = trainiter.next()\n",
    "\n",
    "    print(inputs)\n",
    "    print(model(inputs))\n",
    "\n",
    "    print(mean_squared_error(inputs.detach().numpy(), model(inputs).detach().numpy()))\n",
    "    \n",
    "    print(\"[*] Getting the embeddings and visualizing t-SNE...\")\n",
    "    embeddings=get_embeddings(train_loader, N, model, size_encoded=hidden_layers[-1])\n",
    "    \n",
    "    cmps = connected_components(network)\n",
    "    targets = [0 for i in range(N)]\n",
    "\n",
    "    for i, cmp in enumerate(cmps):\n",
    "        for n in cmp:\n",
    "            targets[n] = i\n",
    "    \n",
    "    visualize_TSNE(embeddings, targets)\n",
    "    \n",
    "    return(embeddings, model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "      DropoutNoise-1                  [-1, 784]               0\n",
      "            Linear-2                  [-1, 500]         392,500\n",
      "           Sigmoid-3                  [-1, 500]               0\n",
      "        BasicBlock-4                  [-1, 500]               0\n",
      "            Linear-5                  [-1, 200]         100,200\n",
      "           Sigmoid-6                  [-1, 200]               0\n",
      "        BasicBlock-7                  [-1, 200]               0\n",
      "            Linear-8                  [-1, 100]          20,100\n",
      "           Sigmoid-9                  [-1, 100]               0\n",
      "       BasicBlock-10                  [-1, 100]               0\n",
      "           Linear-11                  [-1, 200]          20,200\n",
      "          Sigmoid-12                  [-1, 200]               0\n",
      "       BasicBlock-13                  [-1, 200]               0\n",
      "           Linear-14                  [-1, 500]         100,500\n",
      "          Sigmoid-15                  [-1, 500]               0\n",
      "       BasicBlock-16                  [-1, 500]               0\n",
      "           Linear-17                  [-1, 784]         392,784\n",
      "          Sigmoid-18                  [-1, 784]               0\n",
      "       BasicBlock-19                  [-1, 784]               0\n",
      "================================================================\n",
      "Total params: 1,026,284\n",
      "Trainable params: 1,026,284\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 3.91\n",
      "Estimated Total Size (MB): 3.98\n",
      "----------------------------------------------------------------\n",
      "[1,   784] loss: 0.348\n",
      "[2,   784] loss: 0.317\n",
      "[3,   784] loss: 0.315\n",
      "[4,   784] loss: 0.315\n",
      "[5,   784] loss: 0.314\n",
      "[6,   784] loss: 0.314\n",
      "[7,   784] loss: 0.314\n",
      "[8,   784] loss: 0.314\n",
      "[9,   784] loss: 0.314\n",
      "[10,   784] loss: 0.270\n",
      "[11,   784] loss: 0.235\n",
      "[12,   784] loss: 0.230\n",
      "[13,   784] loss: 0.216\n",
      "[14,   784] loss: 0.154\n",
      "[15,   784] loss: 0.191\n",
      "[16,   784] loss: 0.200\n",
      "[17,   784] loss: 0.140\n",
      "[18,   784] loss: 0.140\n",
      "[19,   784] loss: 0.139\n",
      "[20,   784] loss: 0.139\n",
      "[21,   784] loss: 0.139\n",
      "[22,   784] loss: 0.139\n",
      "[23,   784] loss: 0.139\n",
      "[24,   784] loss: 0.139\n",
      "[25,   784] loss: 0.139\n",
      "[26,   784] loss: 0.139\n",
      "[27,   784] loss: 0.139\n",
      "[28,   784] loss: 0.139\n",
      "[29,   784] loss: 0.139\n",
      "[30,   784] loss: 0.139\n",
      "[31,   784] loss: 0.139\n",
      "[32,   784] loss: 0.139\n",
      "[33,   784] loss: 0.139\n",
      "[34,   784] loss: 0.139\n",
      "[35,   784] loss: 0.139\n",
      "[36,   784] loss: 0.139\n",
      "[37,   784] loss: 0.139\n",
      "[38,   784] loss: 0.139\n",
      "[39,   784] loss: 0.139\n",
      "[40,   784] loss: 0.139\n",
      "[41,   784] loss: 0.139\n",
      "[42,   784] loss: 0.139\n",
      "[43,   784] loss: 0.139\n",
      "[44,   784] loss: 0.139\n",
      "[45,   784] loss: 0.139\n",
      "[46,   784] loss: 0.139\n",
      "[47,   784] loss: 0.139\n",
      "[48,   784] loss: 0.139\n",
      "[49,   784] loss: 0.139\n",
      "[50,   784] loss: 0.139\n",
      "[51,   784] loss: 0.139\n",
      "[52,   784] loss: 0.139\n",
      "[53,   784] loss: 0.139\n",
      "[54,   784] loss: 0.139\n",
      "[55,   784] loss: 0.139\n",
      "[56,   784] loss: 0.139\n",
      "[57,   784] loss: 0.139\n",
      "[58,   784] loss: 0.139\n",
      "[59,   784] loss: 0.139\n",
      "[60,   784] loss: 0.139\n",
      "[61,   784] loss: 0.139\n",
      "[62,   784] loss: 0.139\n",
      "[63,   784] loss: 0.139\n",
      "[64,   784] loss: 0.139\n",
      "[65,   784] loss: 0.139\n",
      "[66,   784] loss: 0.139\n",
      "[67,   784] loss: 0.139\n",
      "[68,   784] loss: 0.139\n",
      "[69,   784] loss: 0.139\n",
      "[70,   784] loss: 0.139\n",
      "[71,   784] loss: 0.139\n",
      "[72,   784] loss: 0.139\n",
      "[73,   784] loss: 0.139\n",
      "[74,   784] loss: 0.139\n",
      "[75,   784] loss: 0.139\n",
      "[76,   784] loss: 0.139\n",
      "[77,   784] loss: 0.139\n",
      "[78,   784] loss: 0.139\n",
      "[79,   784] loss: 0.139\n",
      "[80,   784] loss: 0.139\n",
      "[81,   784] loss: 0.139\n",
      "[82,   784] loss: 0.139\n",
      "[83,   784] loss: 0.139\n",
      "[84,   784] loss: 0.139\n",
      "[85,   784] loss: 0.139\n",
      "[86,   784] loss: 0.139\n",
      "[87,   784] loss: 0.139\n",
      "[88,   784] loss: 0.139\n",
      "[89,   784] loss: 0.139\n",
      "[90,   784] loss: 0.139\n",
      "[91,   784] loss: 0.139\n",
      "[92,   784] loss: 0.139\n",
      "[93,   784] loss: 0.139\n",
      "[94,   784] loss: 0.139\n",
      "[95,   784] loss: 0.139\n",
      "[96,   784] loss: 0.139\n",
      "[97,   784] loss: 0.139\n",
      "[98,   784] loss: 0.139\n",
      "[99,   784] loss: 0.139\n",
      "[100,   784] loss: 0.139\n",
      "Finished Training\n",
      "[*] Visualizing an example's output...\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6041, 0.0000,\n",
      "         0.0000, 0.0000, 1.5630, 0.0000, 0.0000, 1.5844, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.5863, 1.5934, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5593, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.6154, 0.0000, 1.6207, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6136, 0.0000, 1.5799, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5678, 0.0000, 1.5640,\n",
      "         1.6759, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.5665, 1.5818, 0.0000, 0.0000, 1.5637,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5756, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5550, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6237, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6135, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.5680, 0.0000, 1.6409, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.6215, 1.6454, 0.0000, 0.0000, 1.5917, 0.0000, 1.6123, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.5872, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.5746, 0.0000, 1.6437, 0.0000, 0.0000, 0.0000, 1.6356, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.6196, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.6265, 1.5985, 1.5827, 0.0000, 1.5838, 0.0000, 1.5923, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.5764, 0.0000, 1.5549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5875, 0.0000, 0.0000,\n",
      "         0.0000, 1.5689, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5622,\n",
      "         1.5942, 0.0000, 0.0000, 0.0000, 0.0000, 1.5883, 1.6113, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.6428, 0.0000, 1.5793, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.6072, 0.0000, 0.0000, 0.0000, 1.6454, 1.6535,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.6446, 0.0000, 1.6698, 1.6008, 0.0000,\n",
      "         0.0000, 0.0000, 1.6175, 0.0000, 1.6510, 1.6670, 0.0000, 1.6297, 0.0000,\n",
      "         0.0000, 1.6184, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6454, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.6015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.6999, 0.0000, 1.6168, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.6547, 0.0000, 1.6316, 0.0000, 0.0000, 1.5766, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6007, 1.5669,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6522, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.6545, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6020,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.6311, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5667, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.5857, 0.0000, 0.0000, 0.0000, 1.5876, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5610, 0.0000, 0.0000,\n",
      "         0.0000, 1.6079, 0.0000, 1.5560, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.5885, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 1.6603, 1.5888, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.5752, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6256, 0.0000, 0.0000, 1.5702,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.6172, 0.0000, 0.0000, 0.0000, 1.5726,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.5860, 0.0000, 0.0000, 0.0000, 1.6005, 0.0000, 0.0000,\n",
      "         0.0000, 1.6387, 1.6312, 0.0000, 1.5773, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6212, 1.6571, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6086,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.6558, 0.0000, 1.6265, 0.0000, 0.0000, 0.0000, 1.5592, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.5971, 0.0000, 1.5747, 0.0000, 1.5774,\n",
      "         0.0000, 1.6000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6026, 1.6220,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5602, 0.0000,\n",
      "         0.0000, 1.6265, 0.0000, 0.0000, 0.0000, 1.6672, 0.0000, 1.5692, 0.0000,\n",
      "         1.5646, 0.0000, 0.0000, 1.6139, 1.5635, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.6152, 1.5892, 1.6126, 0.0000, 0.0000, 0.0000, 1.5899, 0.0000, 1.6496,\n",
      "         1.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5862, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.5794, 0.0000, 1.6002, 0.0000,\n",
      "         1.5882, 0.0000, 1.6073, 1.6190, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.5819, 0.0000, 1.5890, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.6070, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.6104, 1.5665, 0.0000, 0.0000, 0.0000, 0.0000, 1.6395,\n",
      "         0.0000, 1.6010, 0.0000, 1.5706, 0.0000, 1.6055, 0.0000, 1.6241, 1.6295,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.6016, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.5713, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.5689, 0.0000, 1.5850, 0.0000, 0.0000, 1.6828, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 1.5841, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.5701, 1.6215, 0.0000, 1.6326, 0.0000, 0.0000, 1.5801, 0.0000, 0.0000,\n",
      "         0.0000, 1.6105, 0.0000, 1.5867, 1.6249, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         1.5553, 1.6434, 0.0000, 0.0000, 1.6521, 0.0000, 1.6529, 0.0000, 0.0000,\n",
      "         0.0000, 1.5794, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 1.6601, 0.0000, 0.0000, 1.6341, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000]])\n",
      "tensor([[1.0000e+00, 1.9049e-05, 1.8619e-05, 1.8277e-05, 1.0000e+00, 2.0985e-12,\n",
      "         1.8586e-05, 1.0000e+00, 1.0000e+00, 4.6814e-05, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 4.6156e-05, 1.0000e+00, 4.1361e-12, 4.7366e-05, 2.7039e-12,\n",
      "         4.2813e-05, 4.5684e-05, 1.0000e+00, 1.0000e+00, 2.4105e-12, 1.8956e-05,\n",
      "         1.8994e-05, 4.5706e-05, 1.2226e-12, 1.7863e-05, 4.7054e-05, 1.8886e-05,\n",
      "         3.8088e-05, 4.7485e-05, 1.9178e-05, 1.0000e+00, 3.6308e-12, 1.9382e-05,\n",
      "         6.7070e-12, 1.8610e-05, 3.6149e-12, 4.7154e-05, 1.0000e+00, 5.6745e-12,\n",
      "         1.0000e+00, 4.4993e-05, 8.1697e-12, 5.9568e-12, 6.6661e-12, 3.6934e-12,\n",
      "         1.8596e-05, 1.0000e+00, 1.0000e+00, 5.1144e-12, 1.0000e+00, 4.6215e-05,\n",
      "         4.7997e-05, 4.5233e-05, 2.8768e-12, 1.8191e-05, 4.6646e-05, 4.7055e-05,\n",
      "         1.0000e+00, 4.3803e-12, 1.0000e+00, 1.0000e+00, 7.6173e-12, 1.8996e-05,\n",
      "         4.4719e-05, 4.0697e-12, 6.2066e-12, 1.7724e-05, 4.5168e-05, 1.0000e+00,\n",
      "         3.5002e-12, 4.7044e-05, 4.7019e-05, 3.4060e-05, 1.8481e-05, 1.8648e-05,\n",
      "         3.1233e-12, 5.5831e-12, 1.9093e-05, 1.0000e+00, 5.0414e-12, 4.3721e-05,\n",
      "         1.8640e-05, 1.0000e+00, 1.0000e+00, 1.8173e-05, 1.8488e-06, 1.0000e+00,\n",
      "         4.4770e-05, 1.0036e-11, 1.8188e-05, 6.2736e-12, 4.7439e-05, 4.7055e-05,\n",
      "         1.8279e-05, 1.0000e+00, 2.5548e-12, 1.0000e+00, 3.5223e-12, 4.6376e-05,\n",
      "         4.7186e-05, 4.5242e-05, 1.8008e-05, 1.0000e+00, 1.1135e-11, 3.6418e-12,\n",
      "         1.8009e-05, 4.5748e-05, 1.7924e-05, 4.7063e-05, 4.6321e-05, 1.0000e+00,\n",
      "         4.4910e-05, 4.3121e-05, 4.6514e-12, 1.8800e-05, 9.9222e-12, 1.0000e+00,\n",
      "         1.9031e-05, 5.3324e-12, 4.6752e-05, 1.0000e+00, 1.1560e-11, 1.8542e-05,\n",
      "         2.3442e-07, 4.7287e-05, 4.5868e-05, 1.8251e-05, 4.4284e-05, 4.8087e-12,\n",
      "         1.8268e-05, 4.7267e-05, 3.5591e-12, 1.0000e+00, 2.0858e-12, 1.0000e+00,\n",
      "         4.7061e-05, 8.2356e-12, 3.4424e-12, 4.5513e-05, 1.8733e-05, 4.4184e-05,\n",
      "         1.0000e+00, 1.0000e+00, 1.8765e-05, 1.0000e+00, 1.0000e+00, 5.4157e-12,\n",
      "         1.0000e+00, 4.6804e-05, 1.4296e-12, 4.7461e-05, 1.8296e-05, 3.2902e-12,\n",
      "         3.9997e-05, 1.0000e+00, 4.6438e-05, 6.4688e-12, 7.6277e-08, 6.1140e-12,\n",
      "         2.4818e-12, 1.0000e+00, 1.9003e-05, 1.0000e+00, 1.8305e-05, 3.9803e-12,\n",
      "         1.0332e-12, 1.0000e+00, 1.8814e-05, 4.6739e-05, 1.9049e-05, 4.7365e-05,\n",
      "         4.7003e-05, 1.0000e+00, 1.8794e-05, 4.6074e-05, 1.8757e-05, 3.2435e-05,\n",
      "         1.8613e-05, 1.0000e+00, 1.0000e+00, 1.0000e+00, 4.4591e-05, 1.0000e+00,\n",
      "         1.8939e-05, 1.0000e+00, 1.0000e+00, 1.4344e-11, 4.7774e-05, 6.8491e-12,\n",
      "         9.5522e-12, 4.7151e-05, 1.7768e-05, 1.8908e-05, 2.1316e-12, 1.8246e-05,\n",
      "         4.6872e-05, 1.0000e+00, 4.5695e-05, 1.0000e+00, 4.7993e-12, 1.8473e-05,\n",
      "         3.7648e-05, 1.0000e+00, 2.7576e-12, 9.3802e-12, 4.3644e-05, 1.9254e-05,\n",
      "         1.8475e-05, 3.1420e-12, 4.2400e-05, 1.0000e+00, 1.0673e-11, 6.1693e-12,\n",
      "         1.8861e-05, 1.0000e+00, 1.2752e-05, 1.9410e-05, 4.7073e-05, 8.8819e-12,\n",
      "         1.9208e-05, 4.4956e-05, 4.3172e-05, 1.6628e-12, 1.0000e+00, 3.5286e-12,\n",
      "         3.6265e-05, 4.7071e-05, 4.0504e-05, 4.3330e-05, 1.8054e-05, 1.0000e+00,\n",
      "         1.0000e+00, 4.0483e-05, 4.2142e-05, 4.5959e-05, 4.1353e-05, 1.0000e+00,\n",
      "         1.0000e+00, 1.8864e-05, 1.8485e-05, 1.9097e-05, 4.7225e-05, 4.4874e-05,\n",
      "         1.8827e-05, 1.0000e+00, 3.7482e-05, 1.0000e+00, 1.0000e+00, 5.8085e-12,\n",
      "         1.8135e-05, 4.5088e-05, 4.7158e-05, 1.0000e+00, 1.8759e-05, 1.8758e-05,\n",
      "         2.3800e-12, 1.0000e+00, 1.0000e+00, 1.9043e-05, 1.8256e-05, 4.6798e-05,\n",
      "         3.7978e-12, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 7.0065e-12,\n",
      "         4.0915e-05, 1.0000e+00, 1.0000e+00, 1.8318e-05, 1.0000e+00, 1.0000e+00,\n",
      "         1.7152e-05, 1.0000e+00, 4.7085e-05, 4.2983e-05, 1.0000e+00, 1.0000e+00,\n",
      "         1.1927e-11, 4.6579e-05, 1.9227e-05, 4.7401e-05, 5.8647e-12, 6.8520e-12,\n",
      "         2.5705e-12, 1.8777e-05, 4.1140e-12, 1.8689e-05, 1.9206e-05, 1.9215e-05,\n",
      "         6.3915e-12, 1.0000e+00, 4.8807e-12, 6.6050e-13, 1.9706e-05, 2.9310e-12,\n",
      "         1.8853e-05, 3.1808e-12, 5.9593e-12, 4.2890e-05, 1.8697e-05, 1.7786e-05,\n",
      "         1.0000e+00, 2.2394e-12, 4.8146e-12, 1.8334e-05, 1.8505e-05, 4.5946e-05,\n",
      "         1.8404e-05, 4.5783e-05, 7.1681e-12, 3.8421e-05, 1.8896e-05, 4.6780e-05,\n",
      "         1.0000e+00, 5.8757e-12, 1.0000e+00, 7.6017e-12, 1.8734e-05, 1.2493e-08,\n",
      "         4.6254e-05, 1.0000e+00, 4.5114e-05, 1.0000e+00, 4.3624e-12, 1.8025e-05,\n",
      "         1.0000e+00, 7.9966e-12, 4.6466e-05, 4.3745e-05, 1.0000e+00, 4.6186e-05,\n",
      "         1.2898e-06, 1.8029e-05, 4.3936e-12, 4.2193e-05, 1.0000e+00, 1.0000e+00,\n",
      "         1.0395e-05, 6.2494e-12, 4.6976e-05, 2.3729e-12, 2.2285e-12, 4.3288e-05,\n",
      "         1.8315e-05, 4.5293e-05, 2.1866e-12, 1.8411e-05, 4.6840e-05, 1.8732e-05,\n",
      "         4.6545e-05, 1.8834e-05, 4.6392e-05, 1.0000e+00, 2.3739e-12, 1.8997e-05,\n",
      "         4.7718e-12, 1.8521e-05, 4.4228e-05, 8.1655e-12, 4.6541e-05, 1.7055e-12,\n",
      "         8.4331e-12, 1.8849e-05, 4.6065e-05, 1.8166e-05, 1.0000e+00, 1.0000e+00,\n",
      "         4.2649e-05, 4.7017e-05, 3.5157e-12, 4.6532e-05, 1.8470e-05, 4.7199e-05,\n",
      "         3.6839e-12, 3.7272e-12, 2.5267e-12, 4.8952e-05, 2.5253e-12, 1.8313e-05,\n",
      "         1.7769e-05, 1.9268e-12, 1.8481e-05, 5.0571e-12, 1.0000e+00, 4.6903e-05,\n",
      "         4.6242e-05, 5.7951e-12, 4.0631e-05, 1.8285e-05, 1.8767e-05, 1.0000e+00,\n",
      "         1.7693e-05, 4.4555e-05, 1.0000e+00, 8.1922e-12, 4.5918e-05, 1.8586e-05,\n",
      "         4.0682e-12, 1.0000e+00, 1.8454e-05, 1.0000e+00, 1.8934e-05, 1.8586e-05,\n",
      "         1.8385e-05, 4.6538e-05, 3.6849e-12, 1.0000e+00, 4.7279e-05, 1.9086e-05,\n",
      "         4.5203e-05, 6.8398e-12, 1.0000e+00, 8.6281e-12, 3.6314e-05, 1.7550e-05,\n",
      "         1.0000e+00, 4.6826e-05, 1.8879e-05, 4.0545e-05, 1.8003e-05, 6.2947e-12,\n",
      "         1.9019e-05, 2.6035e-12, 4.5124e-05, 1.0000e+00, 1.8626e-05, 1.0572e-12,\n",
      "         4.5412e-12, 1.0000e+00, 1.8301e-05, 1.0000e+00, 8.1395e-12, 1.0000e+00,\n",
      "         6.4231e-12, 1.8692e-05, 4.6812e-05, 4.7467e-05, 1.8427e-05, 1.4971e-12,\n",
      "         1.9088e-05, 1.0000e+00, 4.5943e-05, 4.5892e-05, 1.8730e-05, 3.9319e-12,\n",
      "         1.9599e-05, 1.0000e+00, 1.0000e+00, 4.5563e-12, 4.6464e-05, 5.9513e-12,\n",
      "         1.8879e-05, 1.0739e-11, 1.2842e-12, 1.0000e+00, 1.8218e-05, 4.5925e-05,\n",
      "         9.7054e-12, 1.8557e-05, 1.8938e-05, 4.7768e-12, 4.1203e-12, 3.9303e-05,\n",
      "         9.4611e-12, 5.6365e-12, 4.6920e-05, 1.8581e-05, 1.0000e+00, 1.0000e+00,\n",
      "         4.4790e-05, 1.9279e-05, 1.0000e+00, 1.8604e-05, 4.7772e-05, 1.8329e-05,\n",
      "         1.8457e-05, 1.0000e+00, 4.3403e-05, 1.0000e+00, 2.4084e-12, 1.0000e+00,\n",
      "         4.6832e-05, 1.1823e-11, 1.8313e-05, 1.8471e-05, 4.6133e-05, 1.4317e-05,\n",
      "         3.5316e-12, 1.1899e-11, 1.8729e-05, 4.3727e-12, 1.6965e-05, 1.0000e+00,\n",
      "         6.3917e-12, 7.9749e-12, 1.8660e-05, 1.0000e+00, 1.8645e-05, 4.3729e-12,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 4.2457e-05, 1.0000e+00, 4.6876e-05,\n",
      "         4.6378e-05, 1.8653e-05, 1.9021e-05, 3.3880e-12, 5.9184e-12, 1.8159e-05,\n",
      "         1.0143e-11, 4.0173e-12, 1.0000e+00, 1.0000e+00, 1.8997e-05, 3.3929e-12,\n",
      "         2.4135e-06, 1.0000e+00, 4.4736e-05, 1.8434e-05, 1.8935e-05, 1.8672e-05,\n",
      "         4.3280e-05, 4.6906e-05, 1.0000e+00, 1.8128e-05, 1.2461e-12, 4.7026e-05,\n",
      "         4.7307e-05, 4.1234e-12, 1.8563e-05, 4.2781e-05, 1.8011e-05, 9.9861e-12,\n",
      "         1.0000e+00, 5.8290e-12, 1.0000e+00, 1.8865e-05, 4.7465e-05, 7.0124e-12,\n",
      "         1.0000e+00, 1.3756e-12, 2.1343e-12, 1.8670e-05, 4.4805e-05, 4.6577e-05,\n",
      "         4.7461e-05, 1.0000e+00, 1.8646e-05, 1.0000e+00, 1.6268e-05, 1.0000e+00,\n",
      "         1.8625e-05, 1.0000e+00, 6.0403e-12, 6.9548e-07, 1.8176e-05, 1.0000e+00,\n",
      "         1.8843e-05, 1.0000e+00, 1.0000e+00, 2.9033e-05, 4.1374e-05, 3.9708e-12,\n",
      "         6.6611e-12, 2.1314e-12, 4.2165e-05, 1.8360e-05, 1.0000e+00, 4.3666e-05,\n",
      "         4.5877e-05, 1.0000e+00, 1.8939e-05, 4.3032e-12, 1.0000e+00, 1.0000e+00,\n",
      "         4.6032e-06, 1.0000e+00, 4.7703e-05, 1.0000e+00, 3.1309e-12, 6.4570e-12,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 2.8413e-12, 4.6626e-05, 4.6548e-05,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8874e-05, 4.6347e-05, 1.0000e+00,\n",
      "         1.0000e+00, 1.8395e-05, 1.0000e+00, 1.0000e+00, 5.0134e-12, 1.0000e+00,\n",
      "         4.6804e-12, 4.3260e-05, 1.0000e+00, 3.3424e-12, 1.0000e+00, 1.0000e+00,\n",
      "         6.7949e-12, 4.7528e-05, 4.3692e-05, 3.7675e-12, 4.7064e-12, 1.0000e+00,\n",
      "         4.6381e-05, 1.0000e+00, 4.6795e-05, 1.0000e+00, 4.5039e-05, 1.0000e+00,\n",
      "         1.0000e+00, 1.0979e-11, 3.8178e-12, 1.3560e-12, 1.8678e-05, 4.5297e-05,\n",
      "         6.9405e-12, 4.6777e-05, 1.0000e+00, 2.6297e-12, 1.0000e+00, 1.8137e-05,\n",
      "         4.5926e-05, 3.2669e-12, 4.5714e-12, 4.6971e-05, 1.9306e-05, 4.2242e-12,\n",
      "         4.6936e-05, 1.0000e+00, 4.6672e-05, 1.8833e-05, 1.8350e-05, 6.8046e-12,\n",
      "         4.5799e-05, 4.4448e-05, 1.0000e+00, 4.4845e-05, 3.9791e-12, 4.2862e-05,\n",
      "         6.1680e-12, 1.0000e+00, 1.0681e-12, 4.6860e-05, 1.9165e-05, 3.1423e-12,\n",
      "         4.3755e-05, 1.8641e-05, 1.8568e-05, 1.8952e-05, 1.9131e-05, 1.8229e-05,\n",
      "         1.7783e-05, 4.7477e-05, 1.0000e+00, 1.0000e+00, 1.8998e-05, 2.5241e-05,\n",
      "         4.6234e-05, 1.8403e-05, 1.0000e+00, 4.6652e-12, 1.0000e+00, 1.8911e-05,\n",
      "         1.0000e+00, 4.4508e-05, 1.0000e+00, 3.2561e-12, 1.0000e+00, 1.0000e+00,\n",
      "         4.6286e-05, 4.6806e-05, 4.6206e-05, 2.6310e-12, 1.0000e+00, 4.6741e-05,\n",
      "         4.7133e-05, 1.8255e-05, 4.6506e-05, 1.0000e+00, 8.2932e-12, 2.6855e-12,\n",
      "         4.4774e-12, 1.8158e-05, 1.0000e+00, 4.6410e-05, 4.6969e-05, 2.9453e-12,\n",
      "         1.8579e-05, 4.7374e-05, 1.0000e+00, 1.8676e-05, 1.0000e+00, 4.6238e-05,\n",
      "         1.9187e-05, 1.0000e+00, 4.4646e-12, 1.6487e-11, 1.8701e-05, 3.2881e-12,\n",
      "         4.6922e-05, 1.0000e+00, 1.9817e-05, 4.7032e-05, 6.0827e-12, 4.9229e-12,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.6284e-11, 4.6865e-05,\n",
      "         1.0000e+00, 4.6068e-05, 1.0000e+00, 1.8261e-05, 1.0000e+00, 1.9421e-05,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.8527e-05, 1.8079e-05, 1.8544e-05,\n",
      "         1.0000e+00, 1.0000e+00, 4.5992e-05, 1.9404e-05, 1.0000e+00, 1.8588e-05,\n",
      "         1.0000e+00, 1.9258e-05, 8.5680e-13, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
      "         6.2676e-12, 4.3581e-05, 7.9027e-12, 1.7127e-12, 4.3549e-05, 5.7025e-12,\n",
      "         1.9369e-05, 1.7019e-11, 1.9127e-05, 3.9840e-12, 1.8533e-05, 1.8572e-05,\n",
      "         1.5809e-12, 1.1565e-11, 3.0414e-12, 6.5104e-12, 3.4542e-12, 7.4729e-12,\n",
      "         1.0000e+00, 4.6912e-05, 1.8664e-05, 1.0000e+00, 3.7665e-12, 1.8376e-05,\n",
      "         1.8340e-05, 1.0000e+00, 1.0000e+00, 3.9143e-05, 1.8643e-05, 4.6624e-05,\n",
      "         4.3417e-05, 4.1959e-05, 2.0957e-12, 1.8590e-05]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "0.12807424\n",
      "[*] Getting the embeddings and visualizing t-SNE...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_drugs, _, _ = dngr_pipeline(dd_net, N_rand_drugs, [500, 200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in log\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "      DropoutNoise-1                 [-1, 1000]               0\n",
      "            Linear-2                  [-1, 500]         500,500\n",
      "           Sigmoid-3                  [-1, 500]               0\n",
      "        BasicBlock-4                  [-1, 500]               0\n",
      "            Linear-5                  [-1, 200]         100,200\n",
      "           Sigmoid-6                  [-1, 200]               0\n",
      "        BasicBlock-7                  [-1, 200]               0\n",
      "            Linear-8                  [-1, 100]          20,100\n",
      "           Sigmoid-9                  [-1, 100]               0\n",
      "       BasicBlock-10                  [-1, 100]               0\n",
      "           Linear-11                  [-1, 200]          20,200\n",
      "          Sigmoid-12                  [-1, 200]               0\n",
      "       BasicBlock-13                  [-1, 200]               0\n",
      "           Linear-14                  [-1, 500]         100,500\n",
      "          Sigmoid-15                  [-1, 500]               0\n",
      "       BasicBlock-16                  [-1, 500]               0\n",
      "           Linear-17                 [-1, 1000]         501,000\n",
      "          Sigmoid-18                 [-1, 1000]               0\n",
      "       BasicBlock-19                 [-1, 1000]               0\n",
      "================================================================\n",
      "Total params: 1,242,500\n",
      "Trainable params: 1,242,500\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 4.74\n",
      "Estimated Total Size (MB): 4.81\n",
      "----------------------------------------------------------------\n",
      "[1,  1000] loss: 0.408\n",
      "[2,  1000] loss: 0.348\n",
      "[3,  1000] loss: 0.303\n",
      "[4,  1000] loss: 0.269\n",
      "[5,  1000] loss: 0.259\n",
      "[6,  1000] loss: 0.258\n",
      "[7,  1000] loss: 0.242\n",
      "[8,  1000] loss: 0.225\n",
      "[9,  1000] loss: 0.224\n",
      "[10,  1000] loss: 0.224\n",
      "[11,  1000] loss: 0.224\n",
      "[12,  1000] loss: 0.224\n",
      "[13,  1000] loss: 0.224\n",
      "[14,  1000] loss: 0.224\n",
      "[15,  1000] loss: 0.224\n",
      "[16,  1000] loss: 0.224\n",
      "[17,  1000] loss: 0.224\n",
      "[18,  1000] loss: 0.224\n",
      "[19,  1000] loss: 0.224\n",
      "[20,  1000] loss: 0.224\n",
      "[21,  1000] loss: 0.224\n",
      "[22,  1000] loss: 0.224\n",
      "[23,  1000] loss: 0.224\n",
      "[24,  1000] loss: 0.224\n",
      "[25,  1000] loss: 0.224\n",
      "[26,  1000] loss: 0.224\n",
      "[27,  1000] loss: 0.224\n",
      "[28,  1000] loss: 0.224\n",
      "[29,  1000] loss: 0.224\n",
      "[30,  1000] loss: 0.224\n",
      "[31,  1000] loss: 0.224\n",
      "[32,  1000] loss: 0.224\n",
      "[33,  1000] loss: 0.224\n",
      "[34,  1000] loss: 0.224\n",
      "[35,  1000] loss: 0.224\n",
      "[36,  1000] loss: 0.224\n",
      "[37,  1000] loss: 0.224\n",
      "[38,  1000] loss: 0.224\n",
      "[39,  1000] loss: 0.224\n",
      "[40,  1000] loss: 0.224\n",
      "[41,  1000] loss: 0.224\n",
      "[42,  1000] loss: 0.224\n",
      "[43,  1000] loss: 0.224\n",
      "[44,  1000] loss: 0.224\n",
      "[45,  1000] loss: 0.224\n",
      "[46,  1000] loss: 0.224\n",
      "[47,  1000] loss: 0.224\n",
      "[48,  1000] loss: 0.224\n",
      "[49,  1000] loss: 0.224\n",
      "[50,  1000] loss: 0.224\n",
      "[51,  1000] loss: 0.224\n",
      "[52,  1000] loss: 0.224\n",
      "[53,  1000] loss: 0.224\n",
      "[54,  1000] loss: 0.224\n",
      "[55,  1000] loss: 0.224\n",
      "[56,  1000] loss: 0.224\n",
      "[57,  1000] loss: 0.224\n",
      "[58,  1000] loss: 0.224\n",
      "[59,  1000] loss: 0.224\n",
      "[60,  1000] loss: 0.224\n",
      "[61,  1000] loss: 0.224\n",
      "[62,  1000] loss: 0.224\n",
      "[63,  1000] loss: 0.224\n",
      "[64,  1000] loss: 0.224\n",
      "[65,  1000] loss: 0.224\n",
      "[66,  1000] loss: 0.224\n",
      "[67,  1000] loss: 0.224\n",
      "[68,  1000] loss: 0.224\n",
      "[69,  1000] loss: 0.224\n",
      "[70,  1000] loss: 0.224\n",
      "[71,  1000] loss: 0.224\n",
      "[72,  1000] loss: 0.224\n",
      "[73,  1000] loss: 0.224\n",
      "[74,  1000] loss: 0.224\n",
      "[75,  1000] loss: 0.224\n",
      "[76,  1000] loss: 0.224\n",
      "[77,  1000] loss: 0.224\n",
      "[78,  1000] loss: 0.224\n",
      "[79,  1000] loss: 0.224\n",
      "[80,  1000] loss: 0.224\n",
      "[81,  1000] loss: 0.224\n",
      "[82,  1000] loss: 0.224\n",
      "[83,  1000] loss: 0.224\n",
      "[84,  1000] loss: 0.224\n",
      "[85,  1000] loss: 0.224\n",
      "[86,  1000] loss: 0.224\n",
      "[87,  1000] loss: 0.224\n",
      "[88,  1000] loss: 0.224\n",
      "[89,  1000] loss: 0.224\n",
      "[90,  1000] loss: 0.224\n",
      "[91,  1000] loss: 0.224\n",
      "[92,  1000] loss: 0.224\n",
      "[93,  1000] loss: 0.224\n",
      "[94,  1000] loss: 0.224\n",
      "[95,  1000] loss: 0.224\n",
      "[96,  1000] loss: 0.224\n",
      "[97,  1000] loss: 0.224\n",
      "[98,  1000] loss: 0.224\n",
      "[99,  1000] loss: 0.224\n",
      "[100,  1000] loss: 0.224\n",
      "Finished Training\n",
      "[*] Visualizing an example's output...\n",
      "tensor([[0.0000, 0.0000, 2.5989, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 2.6676, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 2.5226, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.5806, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5296,\n",
      "         0.0000, 0.0000, 0.0000, 0.6392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.6286, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 2.5557, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 2.5197, 0.0000, 0.0000, 0.0000, 0.5789, 0.0000,\n",
      "         2.7255, 0.5513, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5120, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.6109, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.5225, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4817, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5442,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 2.5543, 0.0000, 0.0000, 0.5786, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.6081, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.5837, 0.0000, 2.4900, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5343, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.6420, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6399, 2.6005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5517, 2.6157,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         2.6275, 0.0000, 2.5597, 0.0000, 0.0000, 0.0000, 0.0000, 0.6380, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 2.6438, 0.0000, 0.0000, 0.0000, 0.0000, 2.6852, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 2.5535, 0.0000, 2.6404, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 2.5530, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         2.5846, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.6259,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5863, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5419, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.4993, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         2.6836, 2.6406, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5744,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5678, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.5736, 2.5749, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.6075, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.6036, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.5569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5636, 0.0000,\n",
      "         2.5634, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 2.5824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 2.6355, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         2.6673, 0.0000, 0.0000, 0.0000, 2.5875, 0.0000, 0.0000, 2.7006, 0.0000,\n",
      "         0.0000, 2.6245, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 2.6458, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.6066, 0.0000, 0.0000, 0.5681, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5961, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.5740, 2.6533, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.6003, 0.0000, 0.0000, 0.0000, 0.0000, 2.6242, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6752, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.6141, 0.0000, 0.0000, 2.5817,\n",
      "         2.5871, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 2.5122, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5682, 0.0000, 2.6799, 0.6045,\n",
      "         2.5522, 0.0000, 0.0000, 2.6857, 0.0000, 2.6064, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 2.5796, 0.0000, 2.5325, 2.6066, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 2.6453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         2.5888, 2.5694, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         2.6740, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5109, 0.0000,\n",
      "         2.5530, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5713, 0.0000, 0.0000,\n",
      "         0.0000, 2.5948, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         2.5881, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.5888, 2.5608, 2.5799, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.6599, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 2.5903, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.6406, 0.0000, 0.0000, 0.0000, 0.0000, 0.6399, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.6275, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 2.5107, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5544, 0.0000,\n",
      "         0.0000]])\n",
      "tensor([[1.0000e+00, 7.5702e-14, 1.0000e+00, 2.8069e-11, 1.1638e-08, 1.0000e+00,\n",
      "         2.7781e-10, 1.0000e+00, 1.0000e+00, 3.1867e-05, 1.0000e+00, 7.9235e-07,\n",
      "         1.0000e+00, 1.0000e+00, 2.9333e-10, 8.3091e-11, 8.8175e-13, 7.6016e-08,\n",
      "         1.6368e-10, 4.2090e-10, 1.1870e-14, 1.0000e+00, 2.3309e-12, 2.4826e-08,\n",
      "         1.6960e-14, 8.1340e-11, 3.1981e-05, 8.4711e-07, 6.1217e-08, 1.0000e+00,\n",
      "         2.1969e-12, 6.0604e-11, 4.7093e-15, 4.2982e-10, 4.1561e-07, 5.0153e-13,\n",
      "         1.0000e+00, 3.6828e-15, 9.6498e-09, 1.3408e-06, 1.7711e-06, 1.0000e+00,\n",
      "         2.4095e-13, 1.0000e+00, 1.0000e+00, 3.9538e-15, 5.1403e-08, 8.8518e-07,\n",
      "         1.0000e+00, 9.0703e-13, 6.3578e-07, 2.6444e-08, 1.2131e-06, 9.3669e-15,\n",
      "         5.2667e-07, 7.0302e-11, 3.1652e-05, 1.5225e-06, 1.6160e-10, 1.0000e+00,\n",
      "         6.9643e-08, 8.6542e-11, 2.1554e-10, 1.1410e-10, 7.6941e-07, 1.0000e+00,\n",
      "         5.0661e-08, 6.7215e-07, 2.6046e-08, 1.1223e-14, 1.0051e-07, 2.6941e-07,\n",
      "         9.6674e-11, 1.0950e-06, 3.1701e-05, 1.0000e+00, 8.4397e-11, 2.0353e-08,\n",
      "         1.3801e-06, 1.0000e+00, 8.0274e-15, 1.0000e+00, 1.0000e+00, 1.7016e-11,\n",
      "         1.2238e-06, 2.1098e-06, 1.0000e+00, 1.1381e-10, 8.1032e-11, 1.4020e-13,\n",
      "         8.3522e-11, 6.0712e-08, 1.4268e-10, 1.6308e-06, 1.3740e-10, 1.0000e+00,\n",
      "         7.3337e-07, 6.3975e-15, 1.0150e-10, 3.1904e-05, 1.5640e-11, 1.9029e-10,\n",
      "         5.8407e-15, 4.1865e-15, 1.0000e+00, 6.1572e-15, 6.7592e-15, 7.3078e-15,\n",
      "         2.6841e-10, 2.1369e-10, 1.4206e-14, 1.3891e-06, 2.1163e-10, 1.0000e+00,\n",
      "         8.5821e-11, 3.5957e-08, 1.5000e-10, 1.3728e-14, 2.4039e-08, 2.5320e-10,\n",
      "         6.0500e-15, 1.0000e+00, 9.7634e-07, 3.2160e-05, 4.0675e-08, 1.0000e+00,\n",
      "         1.4968e-06, 7.8618e-07, 8.1215e-11, 5.6578e-11, 1.3251e-06, 1.2843e-10,\n",
      "         1.0000e+00, 1.0000e+00, 1.4803e-06, 3.2082e-05, 6.5688e-08, 1.8783e-06,\n",
      "         3.1938e-05, 1.2596e-06, 1.1128e-14, 2.0067e-10, 1.1859e-06, 1.0000e+00,\n",
      "         1.0000e+00, 5.6697e-12, 7.5209e-15, 8.1536e-15, 2.6737e-10, 1.2508e-06,\n",
      "         1.0000e+00, 3.1783e-05, 5.5382e-14, 1.9691e-10, 8.4129e-13, 1.9173e-10,\n",
      "         1.5962e-10, 1.0000e+00, 2.0849e-12, 2.7342e-08, 1.0000e+00, 5.7442e-07,\n",
      "         1.0000e+00, 1.0000e+00, 1.3237e-06, 1.2847e-06, 2.4999e-06, 1.0588e-06,\n",
      "         1.1459e-06, 1.6954e-12, 4.8871e-07, 7.5780e-07, 3.2042e-05, 3.1811e-05,\n",
      "         1.0000e+00, 2.6860e-15, 1.0000e+00, 4.2994e-11, 4.5448e-13, 1.1519e-07,\n",
      "         5.4583e-08, 3.1723e-05, 2.7060e-08, 2.4676e-10, 4.1964e-07, 3.7117e-15,\n",
      "         1.1221e-10, 1.0000e+00, 3.1739e-05, 4.4364e-08, 9.5835e-11, 2.0467e-10,\n",
      "         2.4677e-08, 1.0000e+00, 1.7956e-13, 1.0000e+00, 1.0000e+00, 5.1509e-08,\n",
      "         4.7637e-12, 8.0589e-07, 1.1343e-14, 1.5210e-08, 1.0000e+00, 2.3742e-06,\n",
      "         1.0000e+00, 1.2930e-10, 7.3624e-07, 3.1604e-05, 5.9517e-14, 2.0528e-10,\n",
      "         3.1371e-05, 1.0000e+00, 6.3725e-15, 7.4752e-07, 9.4083e-07, 1.0938e-13,\n",
      "         3.7059e-08, 8.0562e-13, 3.1681e-05, 4.7176e-11, 3.1517e-05, 1.9604e-10,\n",
      "         1.0000e+00, 1.0000e+00, 1.1653e-10, 2.7784e-11, 1.0000e+00, 6.8159e-11,\n",
      "         2.1838e-10, 1.0000e+00, 1.6355e-14, 5.0345e-12, 1.1275e-10, 1.2954e-14,\n",
      "         4.9713e-07, 9.7358e-07, 2.5131e-10, 1.0000e+00, 3.1845e-05, 6.3966e-13,\n",
      "         3.1768e-05, 3.2715e-07, 4.9940e-08, 1.6820e-14, 1.6187e-14, 5.2055e-07,\n",
      "         1.6641e-10, 1.1512e-10, 1.1706e-06, 3.2235e-05, 3.1747e-05, 1.0000e+00,\n",
      "         2.0304e-14, 1.0694e-06, 1.0000e+00, 1.0000e+00, 6.2673e-07, 2.5366e-07,\n",
      "         7.9998e-11, 3.2005e-05, 7.5065e-11, 9.5047e-11, 3.1600e-05, 1.0000e+00,\n",
      "         3.1596e-05, 1.4103e-07, 8.3737e-07, 1.6971e-10, 1.0000e+00, 1.0000e+00,\n",
      "         1.2803e-08, 1.1853e-10, 9.7469e-07, 3.1466e-05, 1.1535e-06, 1.0000e+00,\n",
      "         2.1018e-14, 2.8679e-08, 1.3028e-10, 2.1437e-10, 7.2137e-13, 1.4691e-12,\n",
      "         1.3626e-08, 2.3592e-14, 8.9063e-11, 1.4208e-06, 5.7000e-06, 3.1783e-05,\n",
      "         1.0000e+00, 9.0265e-11, 1.0000e+00, 1.0000e+00, 3.5028e-10, 1.0000e+00,\n",
      "         1.8876e-10, 1.0000e+00, 1.9765e-10, 1.0000e+00, 1.1824e-06, 1.1039e-06,\n",
      "         1.6235e-10, 4.5930e-08, 2.9874e-10, 3.9128e-15, 1.2976e-13, 9.0863e-08,\n",
      "         3.5835e-08, 1.0000e+00, 1.0000e+00, 9.8381e-15, 1.7931e-06, 3.2866e-08,\n",
      "         1.0000e+00, 2.7214e-12, 4.4242e-08, 2.1518e-13, 1.7009e-10, 3.4854e-06,\n",
      "         2.2013e-10, 1.1883e-06, 3.1727e-05, 6.6486e-15, 6.6563e-15, 3.2018e-05,\n",
      "         1.4975e-10, 4.7925e-08, 1.0000e+00, 3.1951e-05, 3.1886e-05, 1.0963e-14,\n",
      "         1.0000e+00, 2.2502e-12, 2.0237e-12, 7.1137e-08, 8.4808e-11, 3.8115e-15,\n",
      "         2.3482e-08, 1.0000e+00, 3.1857e-05, 1.0000e+00, 1.3977e-10, 3.5788e-08,\n",
      "         3.1751e-05, 1.0241e-06, 1.4295e-06, 1.0443e-06, 1.0000e+00, 1.1997e-06,\n",
      "         9.6322e-07, 6.7007e-15, 1.0394e-14, 1.0000e+00, 4.7220e-11, 2.2910e-10,\n",
      "         1.0000e+00, 1.6327e-08, 1.4975e-06, 1.1524e-06, 2.6927e-06, 1.0000e+00,\n",
      "         1.9263e-07, 1.0000e+00, 1.0000e+00, 3.1786e-05, 3.1624e-05, 3.2086e-05,\n",
      "         2.1503e-06, 7.0871e-08, 8.7691e-07, 1.2341e-06, 8.9980e-15, 2.4196e-10,\n",
      "         3.2397e-11, 1.0000e+00, 3.1716e-05, 2.0197e-14, 1.9988e-10, 2.4209e-10,\n",
      "         3.1321e-05, 6.4795e-15, 2.7650e-06, 2.7369e-06, 3.1853e-05, 1.0000e+00,\n",
      "         1.0000e+00, 2.1767e-06, 2.2909e-06, 9.0359e-07, 5.0045e-06, 3.0826e-12,\n",
      "         1.2549e-07, 3.3003e-10, 7.7795e-13, 7.5686e-15, 1.2659e-10, 1.1616e-10,\n",
      "         1.4732e-10, 3.1561e-05, 1.6584e-06, 1.0000e+00, 1.2362e-14, 1.0000e+00,\n",
      "         1.5442e-14, 9.5297e-11, 9.4173e-11, 1.1957e-10, 1.0000e+00, 2.5162e-10,\n",
      "         3.2665e-13, 8.1680e-15, 2.8816e-13, 1.0000e+00, 4.8554e-15, 1.0000e+00,\n",
      "         1.6241e-06, 1.2758e-10, 1.0000e+00, 2.2964e-06, 1.5837e-10, 1.0000e+00,\n",
      "         3.9711e-08, 1.8505e-10, 1.0000e+00, 4.2910e-08, 1.0216e-10, 1.2869e-06,\n",
      "         6.8778e-07, 1.2448e-14, 1.0000e+00, 1.0233e-06, 3.6857e-08, 2.6536e-12,\n",
      "         1.0000e+00, 1.0000e+00, 2.4262e-10, 3.1846e-05, 3.1724e-05, 3.8533e-08,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 3.1563e-05, 1.4139e-12, 7.9238e-15,\n",
      "         5.6253e-13, 3.4649e-06, 1.6482e-14, 2.4681e-11, 1.0000e+00, 2.5402e-08,\n",
      "         6.1447e-13, 1.1190e-06, 1.6967e-07, 1.3777e-10, 3.1926e-05, 8.6232e-08,\n",
      "         2.0182e-06, 1.3690e-12, 2.1243e-06, 8.9255e-13, 5.6822e-08, 1.0000e+00,\n",
      "         1.0000e+00, 7.4299e-15, 7.5881e-15, 7.8390e-11, 3.9606e-06, 1.0403e-14,\n",
      "         3.0919e-10, 2.5395e-10, 1.2399e-06, 1.2136e-07, 7.4833e-07, 1.0000e+00,\n",
      "         3.3749e-12, 1.0000e+00, 3.1792e-12, 7.5475e-08, 1.0540e-07, 9.3710e-07,\n",
      "         1.0000e+00, 1.0000e+00, 1.0000e+00, 1.5669e-06, 1.3863e-14, 1.0000e+00,\n",
      "         2.6880e-12, 3.1860e-05, 2.0356e-06, 2.0860e-10, 1.0000e+00, 4.1457e-07,\n",
      "         1.0000e+00, 2.2980e-06, 1.1440e-06, 5.4383e-07, 1.5615e-08, 1.6993e-10,\n",
      "         1.0000e+00, 1.7878e-08, 1.7238e-06, 3.2680e-10, 2.2556e-06, 6.0630e-08,\n",
      "         1.0000e+00, 3.9058e-08, 5.4565e-15, 7.2689e-14, 1.9179e-10, 1.3532e-06,\n",
      "         3.0007e-13, 1.1791e-06, 1.0845e-10, 1.2157e-06, 2.4639e-10, 1.3549e-06,\n",
      "         8.7967e-15, 8.6895e-15, 9.2535e-14, 1.0262e-06, 1.5220e-06, 2.0876e-11,\n",
      "         1.0715e-10, 8.5312e-15, 7.4304e-07, 1.7475e-10, 3.7380e-08, 1.9561e-10,\n",
      "         2.2201e-06, 3.1691e-05, 3.2017e-05, 3.1542e-05, 2.3480e-06, 1.2730e-10,\n",
      "         1.2448e-06, 3.1833e-05, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.3313e-12,\n",
      "         1.0000e+00, 1.6888e-10, 1.8886e-10, 2.5546e-08, 2.3824e-10, 2.1092e-10,\n",
      "         7.4851e-07, 1.4538e-10, 4.6191e-07, 6.5800e-11, 1.3306e-14, 1.6211e-08,\n",
      "         1.0000e+00, 9.0883e-07, 3.1944e-06, 3.1725e-10, 1.0000e+00, 3.1623e-05,\n",
      "         7.8574e-08, 8.5059e-07, 1.0000e+00, 2.4283e-10, 9.6401e-07, 1.1888e-06,\n",
      "         6.1536e-13, 1.6821e-10, 9.4793e-07, 3.1818e-05, 3.1541e-05, 6.3473e-11,\n",
      "         1.2152e-06, 6.5642e-07, 1.0000e+00, 2.2373e-10, 1.0353e-10, 7.3859e-07,\n",
      "         1.0000e+00, 2.7550e-08, 3.9280e-07, 2.9321e-10, 1.0000e+00, 1.0000e+00,\n",
      "         9.8597e-07, 1.0000e+00, 3.6578e-15, 3.7555e-13, 1.0000e+00, 3.3642e-08,\n",
      "         1.8932e-12, 1.2913e-10, 1.0550e-10, 1.6601e-06, 3.1577e-05, 1.3042e-10,\n",
      "         3.1789e-05, 1.0836e-12, 3.1694e-05, 1.0000e+00, 1.1537e-14, 1.0000e+00,\n",
      "         1.9120e-10, 1.0000e+00, 3.7399e-13, 1.7632e-12, 7.2350e-07, 1.0000e+00,\n",
      "         1.1239e-14, 7.6973e-07, 5.2221e-08, 3.3715e-08, 1.7347e-14, 3.1716e-05,\n",
      "         2.9932e-07, 1.7580e-06, 1.3161e-12, 3.1760e-05, 1.0000e+00, 7.7865e-10,\n",
      "         1.5343e-06, 3.3725e-08, 8.0244e-11, 1.3444e-10, 6.9975e-13, 3.2084e-05,\n",
      "         8.4785e-08, 6.7211e-11, 1.9787e-12, 1.4526e-13, 7.8966e-11, 4.7609e-07,\n",
      "         4.9481e-11, 6.4809e-15, 1.5221e-06, 3.3142e-15, 3.1707e-05, 2.1322e-08,\n",
      "         1.4574e-10, 5.7002e-08, 1.0000e+00, 2.3196e-08, 3.3958e-12, 1.1052e-14,\n",
      "         1.1670e-12, 4.9444e-07, 1.0000e+00, 1.0000e+00, 1.9378e-14, 1.1990e-13,\n",
      "         6.8390e-07, 1.0000e+00, 3.1584e-05, 1.5851e-06, 1.0000e+00, 2.2728e-06,\n",
      "         2.9951e-14, 3.1623e-05, 3.1915e-05, 3.1697e-05, 2.4870e-12, 1.0000e+00,\n",
      "         1.6733e-06, 1.0358e-06, 1.0000e+00, 1.1189e-10, 2.8638e-07, 1.2109e-06,\n",
      "         2.3231e-13, 1.0000e+00, 1.0000e+00, 7.5514e-13, 1.1582e-12, 1.3705e-12,\n",
      "         1.0000e+00, 3.0462e-10, 2.0749e-10, 4.3413e-08, 3.1504e-05, 1.8482e-06,\n",
      "         1.5053e-10, 3.8896e-08, 2.3087e-12, 3.6905e-10, 1.1227e-12, 1.0000e+00,\n",
      "         2.8327e-10, 3.1805e-05, 3.1921e-05, 2.0732e-14, 2.6157e-10, 4.5388e-15,\n",
      "         1.8089e-06, 3.1618e-05, 1.9400e-10, 3.1795e-05, 1.0000e+00, 1.9219e-11,\n",
      "         1.8079e-10, 2.6163e-08, 3.1691e-05, 1.0000e+00, 3.1772e-05, 1.3168e-10,\n",
      "         1.5381e-10, 1.3060e-14, 2.3616e-06, 3.2156e-05, 1.0805e-12, 1.2897e-06,\n",
      "         3.1766e-05, 1.0000e+00, 2.5126e-06, 1.8469e-10, 5.4688e-07, 8.7816e-15,\n",
      "         1.3391e-12, 3.1813e-05, 1.1226e-06, 3.1520e-05, 1.0000e+00, 1.0000e+00,\n",
      "         1.7492e-06, 1.0000e+00, 2.1944e-10, 1.0000e+00, 1.2223e-06, 1.0000e+00,\n",
      "         2.0334e-06, 5.8290e-08, 1.0000e+00, 1.0000e+00, 7.2591e-07, 2.3960e-08,\n",
      "         1.2033e-06, 1.0000e+00, 1.4879e-14, 1.0000e+00, 9.7606e-15, 1.3718e-14,\n",
      "         1.7355e-10, 1.0000e+00, 4.3637e-13, 1.0000e+00, 3.1542e-05, 8.5074e-15,\n",
      "         4.0490e-11, 1.0570e-12, 1.2411e-14, 2.3099e-08, 2.3194e-10, 3.1610e-05,\n",
      "         3.2437e-05, 2.0099e-10, 1.0000e+00, 3.1653e-05, 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00, 1.0000e+00, 1.4928e-10, 1.0000e+00, 6.9979e-07, 1.0000e+00,\n",
      "         1.2991e-12, 1.7231e-10, 1.1376e-12, 3.8271e-08, 1.0000e+00, 2.1184e-12,\n",
      "         1.0000e+00, 8.6058e-11, 1.0000e+00, 1.0000e+00, 6.9272e-11, 7.4978e-07,\n",
      "         2.0457e-13, 6.0562e-07, 1.0000e+00, 1.0000e+00, 7.8181e-14, 9.8591e-15,\n",
      "         1.0563e-10, 3.1219e-07, 4.1701e-11, 1.0000e+00, 1.0000e+00, 3.1620e-05,\n",
      "         9.3150e-07, 9.8198e-08, 1.2396e-06, 6.0984e-11, 3.9072e-08, 1.8700e-12,\n",
      "         3.1753e-05, 1.0000e+00, 1.4242e-10, 3.8372e-12, 1.7465e-07, 1.8809e-12,\n",
      "         1.0000e+00, 4.1008e-07, 2.2778e-06, 1.0000e+00, 1.0000e+00, 5.2313e-15,\n",
      "         1.0000e+00, 1.9607e-10, 2.1436e-08, 2.8222e-13, 1.0000e+00, 8.9177e-07,\n",
      "         1.0000e+00, 1.0000e+00, 7.5175e-11, 9.1555e-15, 1.0000e+00, 1.8293e-14,\n",
      "         1.0000e+00, 1.7480e-10, 6.3518e-07, 3.5424e-07, 1.0000e+00, 3.7976e-10,\n",
      "         3.1890e-05, 3.3271e-08, 3.1954e-05, 7.7951e-07, 2.1544e-13, 1.0962e-10,\n",
      "         1.0000e+00, 1.2775e-10, 1.0000e+00, 3.1746e-05, 3.1424e-05, 2.4697e-08,\n",
      "         1.2258e-13, 2.8892e-11, 3.2220e-05, 3.1393e-05, 1.0000e+00, 9.5894e-07,\n",
      "         7.8898e-13, 6.5028e-08, 1.2678e-06, 1.7584e-08, 1.4678e-10, 1.0532e-06,\n",
      "         2.1519e-08, 7.1313e-15, 1.0000e+00, 1.0000e+00, 1.0000e+00, 3.2025e-05,\n",
      "         2.3835e-12, 1.0287e-06, 1.3135e-10, 3.1553e-05, 1.4955e-13, 1.0000e+00,\n",
      "         1.3992e-06, 1.0756e-14, 3.1913e-05, 6.6087e-15, 4.3125e-08, 1.1834e-08,\n",
      "         3.1915e-05, 1.0000e+00, 9.6714e-11, 9.1240e-15, 1.5065e-12, 5.0742e-08,\n",
      "         3.2114e-05, 5.8450e-07, 7.4256e-07, 1.7623e-12, 1.3357e-10, 1.0775e-10,\n",
      "         1.7586e-06, 5.1270e-07, 2.4798e-12, 1.7622e-06, 3.3146e-12, 1.8598e-08,\n",
      "         3.1808e-05, 7.1603e-07, 3.7015e-13, 3.1870e-05, 1.0000e+00, 1.4753e-14,\n",
      "         4.0691e-07, 1.5813e-06, 1.0539e-10, 3.3060e-11, 1.0000e+00, 1.1516e-12,\n",
      "         1.0660e-10, 3.5186e-15, 3.1594e-05, 1.0000e+00, 1.3892e-12, 1.0000e+00,\n",
      "         6.0597e-13, 6.6556e-08, 5.4972e-08, 1.1997e-07, 4.2492e-07, 1.7669e-10,\n",
      "         2.4308e-08, 5.3568e-13, 2.4446e-10, 1.9330e-10, 1.0000e+00, 5.7760e-08,\n",
      "         1.8642e-10, 1.1363e-06, 1.1099e-14, 2.5899e-10, 1.9985e-14, 1.0000e+00,\n",
      "         2.7355e-08, 3.3928e-07, 2.4527e-06, 4.3703e-15, 1.3752e-08, 1.0000e+00,\n",
      "         1.0000e+00, 3.1656e-05, 1.8444e-12, 7.1151e-07, 7.4978e-07, 1.7468e-14,\n",
      "         8.1779e-07, 2.2702e-11, 1.0569e-07, 1.0000e+00, 3.2827e-10, 5.0584e-15,\n",
      "         1.0000e+00, 3.1672e-05, 1.1760e-12, 6.3251e-15, 6.8955e-13, 1.6431e-10,\n",
      "         8.4004e-08, 8.0729e-07, 1.2965e-08, 7.8012e-11, 1.0000e+00, 3.2514e-15,\n",
      "         1.0000e+00, 5.9028e-10, 1.0000e+00, 2.6153e-12, 1.3472e-10, 8.5160e-15,\n",
      "         2.2810e-13, 1.9460e-08, 7.9274e-11, 3.1841e-05, 1.1302e-10, 1.6782e-10,\n",
      "         3.1593e-05, 1.6208e-10, 9.4957e-11, 8.1869e-15, 3.1419e-05, 5.7032e-12,\n",
      "         1.0000e+00, 9.7050e-15, 2.0383e-10, 7.6021e-08, 1.9229e-10, 1.3693e-06,\n",
      "         1.0000e+00, 2.1572e-12, 1.1357e-10, 9.6825e-11, 1.1630e-06, 3.1974e-05,\n",
      "         2.3859e-14, 1.8460e-06, 1.3147e-06, 3.0423e-08, 2.7566e-10, 1.1091e-14,\n",
      "         1.7428e-10, 4.4030e-07, 2.0127e-06, 1.7808e-06, 1.2913e-06, 3.1826e-05,\n",
      "         3.5174e-11, 1.7312e-06, 9.2639e-15, 1.0000e+00, 1.2602e-06, 3.2884e-12,\n",
      "         2.9287e-10, 1.0000e+00, 1.4180e-06, 6.5999e-11]],\n",
      "       grad_fn=<SigmoidBackward>)\n",
      "0.2855924\n",
      "[*] Getting the embeddings and visualizing t-SNE...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_targets, _, _ = dngr_pipeline(pp_net, N_rand_targets, [500, 200, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of variables: 1400\n",
      "Finding positive and negative examples...\n",
      "Number of positive examples: 392105\n",
      "Number of negative/unlabelled examples: 391895\n",
      "Going to minimize... Maximum number of iterations: 1\n"
     ]
    }
   ],
   "source": [
    "pu_learning(embeddings_drugs, embeddings_targets, dp_net, maxiter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [References]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] X. Zeng, S. Zhu, W. Lu, Z. Liu, J. Huang, Y. Zhou, J. Fang, Y. Huang, H. Guo, L. Li, B. D. Trapp, R. Nussinov, C. Eng, J. Loscalzo, F. Cheng, Target identification among known drugs by deep learning from heterogeneous networks. Chem. Sci.11, 1775–1797 (2020).\n",
    "\n",
    "[2] Shaosheng Cao, Wei Lu, and Qiongkai Xu. 2016. Deep neural networks for learning graph representations. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI'16). AAAI Press, 1145–1152."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
